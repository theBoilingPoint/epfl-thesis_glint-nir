{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import lpips\n",
    "import torch\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = os.path.join(os.getcwd(), 'data', 'bob_clarens')\n",
    "number_of_imgs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft(image):\n",
    "    # Apply FFT\n",
    "    f = np.fft.fft2(image)\n",
    "    # Shift the zero frequency component to the center\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    # Compute the magnitude spectrum\n",
    "    magnitude_spectrum = np.abs(fshift)\n",
    "    return magnitude_spectrum.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae(image1, image2):\n",
    "    # Ensure the images have the same dimensions\n",
    "    assert image1.shape == image2.shape, \"Images must have the same dimensions\"\n",
    "    \n",
    "    # Compute the Mean Absolute Error\n",
    "    mae = np.mean(np.abs(image1 - image2))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "MAE between Reference and GS-IR: 19.7776188203125\n",
      "MAE between Reference and TensoIR: 24.505929799479162\n",
      "MAE between Reference and GTV: 16.144162507812503\n",
      "MAE between Reference and Mine: 20.894783458333333\n"
     ]
    }
   ],
   "source": [
    "mae_0_lst = np.array([])\n",
    "mae_1_lst = np.array([])\n",
    "mae_2_lst = np.array([])\n",
    "mae_3_lst = np.array([])\n",
    "mae_4_lst = np.array([])\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    # Load the images as RGB\n",
    "    ref = np.array(Image.open(os.path.join(imgs_dir, 'ref', f'r_{i}.png')).convert('RGB'))\n",
    "    gsir = np.array(Image.open(os.path.join(imgs_dir, 'gsir', f'r_{i}.png')).convert('RGB'))\n",
    "    tensoir = np.array(Image.open(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png')).convert('RGB'))\n",
    "    gtv = np.array(Image.open(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png')).convert('RGB'))\n",
    "    mine = np.array(Image.open(os.path.join(imgs_dir, 'mine', f'r_{i}.png')).convert('RGB'))\n",
    "\n",
    "    mae_0 = calculate_mae(ref, ref)\n",
    "    mae_1 = calculate_mae(ref, gsir)\n",
    "    mae_2 = calculate_mae(ref, tensoir)\n",
    "    mae_3 = calculate_mae(ref, gtv)\n",
    "    mae_4 = calculate_mae(ref, mine)\n",
    "\n",
    "    mae_0_lst = np.append(mae_0_lst, mae_0)\n",
    "    mae_1_lst = np.append(mae_1_lst, mae_1)\n",
    "    mae_2_lst = np.append(mae_2_lst, mae_2)\n",
    "    mae_3_lst = np.append(mae_3_lst, mae_3)\n",
    "    mae_4_lst = np.append(mae_4_lst, mae_4)\n",
    "        \n",
    "print(f'Sanity Check: {mae_0_lst.mean()}')\n",
    "print(f'MAE between Reference and GS-IR: {mae_1_lst.mean()}')\n",
    "print(f'MAE between Reference and TensoIR: {mae_2_lst.mean()}')\n",
    "print(f'MAE between Reference and GTV: {mae_3_lst.mean()}')\n",
    "print(f'MAE between Reference and Mine: {mae_4_lst.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "MAE between Reference and GS-IR: 23.853976041666666\n",
      "MAE between Reference and TensoIR: 25.565108333333338\n",
      "MAE between Reference and GTV: 17.261838541666666\n",
      "MAE between Reference and Mine: 23.56360260416667\n"
     ]
    }
   ],
   "source": [
    "mae_0_lst = np.array([])\n",
    "mae_1_lst = np.array([])\n",
    "mae_2_lst = np.array([])\n",
    "mae_3_lst = np.array([])\n",
    "mae_4_lst = np.array([])\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    # Load the images as grayscale\n",
    "    ref_gray = cv2.imread(os.path.join(imgs_dir, 'ref', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gsir_gray = cv2.imread(os.path.join(imgs_dir, 'gsir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    tensoir_gray = cv2.imread(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gtv_gray = cv2.imread(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    mine_gray = cv2.imread(os.path.join(imgs_dir, 'mine', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ref_spectrum = compute_fft(ref_gray)\n",
    "    gsir_spectrum = compute_fft(gsir_gray)\n",
    "    tensoir_spectrum = compute_fft(tensoir_gray)\n",
    "    gtv_spectrum = compute_fft(gtv_gray)\n",
    "    mine_spectrum = compute_fft(mine_gray)\n",
    "\n",
    "    mae_0 = calculate_mae(ref_spectrum, ref_spectrum)\n",
    "    mae_1 = calculate_mae(ref, gsir)\n",
    "    mae_2 = calculate_mae(ref, tensoir)\n",
    "    mae_3 = calculate_mae(ref, gtv)\n",
    "    mae_4 = calculate_mae(ref, mine)\n",
    "\n",
    "    mae_0_lst = np.append(mae_0_lst, mae_0)\n",
    "    mae_1_lst = np.append(mae_1_lst, mae_1)\n",
    "    mae_2_lst = np.append(mae_2_lst, mae_2)\n",
    "    mae_3_lst = np.append(mae_3_lst, mae_3)\n",
    "    mae_4_lst = np.append(mae_4_lst, mae_4)\n",
    "\n",
    "print(f'Sanity Check: {mae_0_lst.mean()}')\n",
    "print(f'MAE between Reference and GS-IR: {mae_1_lst.mean()}')\n",
    "print(f'MAE between Reference and TensoIR: {mae_2_lst.mean()}')\n",
    "print(f'MAE between Reference and GTV: {mae_3_lst.mean()}')\n",
    "print(f'MAE between Reference and Mine: {mae_4_lst.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    # Compute the Mean Squared Error between the two images\n",
    "    return np.mean((imageA - imageB) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "MSE between Reference and GS-IR: 4.6380554973958334\n",
      "MSE between Reference and TensoIR: 8.323264820312499\n",
      "MSE between Reference and GTV: 5.023929658854167\n",
      "MSE between Reference and Mine: 5.028422442708333\n"
     ]
    }
   ],
   "source": [
    "mse_0_lst = np.array([])\n",
    "mse_1_lst = np.array([])\n",
    "mse_2_lst = np.array([])\n",
    "mse_3_lst = np.array([])\n",
    "mse_4_lst = np.array([])\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    # Load the images as RGB\n",
    "    ref = np.array(Image.open(os.path.join(imgs_dir, 'ref', f'r_{i}.png')).convert('RGB'))\n",
    "    gsir = np.array(Image.open(os.path.join(imgs_dir, 'gsir', f'r_{i}.png')).convert('RGB'))\n",
    "    tensoir = np.array(Image.open(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png')).convert('RGB'))\n",
    "    gtv = np.array(Image.open(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png')).convert('RGB'))\n",
    "    mine = np.array(Image.open(os.path.join(imgs_dir, 'mine', f'r_{i}.png')).convert('RGB'))\n",
    "\n",
    "    mse_0 = mse(ref, ref)\n",
    "    mse_1 = mse(ref, gsir)\n",
    "    mse_2 = mse(ref, tensoir)\n",
    "    mse_3 = mse(ref, gtv)\n",
    "    mse_4 = mse(ref, mine)\n",
    "\n",
    "    mse_0_lst = np.append(mse_0_lst, mse_0)\n",
    "    mse_1_lst = np.append(mse_1_lst, mse_1)\n",
    "    mse_2_lst = np.append(mse_2_lst, mse_2)\n",
    "    mse_3_lst = np.append(mse_3_lst, mse_3)\n",
    "    mse_4_lst = np.append(mse_4_lst, mse_4)\n",
    "\n",
    "print(f'Sanity Check: {mse_0_lst.mean()}')\n",
    "print(f'MSE between Reference and GS-IR: {mse_1_lst.mean()}')\n",
    "print(f'MSE between Reference and TensoIR: {mse_2_lst.mean()}')\n",
    "print(f'MSE between Reference and GTV: {mse_3_lst.mean()}')\n",
    "print(f'MSE between Reference and Mine: {mse_4_lst.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "MSE between Reference and GS-IR: 54801073.13\n",
      "MSE between Reference and TensoIR: 43108284.6425\n",
      "MSE between Reference and GTV: 38507604.7\n",
      "MSE between Reference and Mine: 52868310.805\n"
     ]
    }
   ],
   "source": [
    "# Compute MSE between the reference spectrum and each reconstruction spectrum\n",
    "mse_0_lst = np.array([])\n",
    "mse_1_lst = np.array([])\n",
    "mse_2_lst = np.array([])\n",
    "mse_3_lst = np.array([])\n",
    "mse_4_lst = np.array([])\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    # Load the images as grayscale\n",
    "    ref_gray = cv2.imread(os.path.join(imgs_dir, 'ref', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gsir_gray = cv2.imread(os.path.join(imgs_dir, 'gsir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    tensoir_gray = cv2.imread(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gtv_gray = cv2.imread(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    mine_gray = cv2.imread(os.path.join(imgs_dir, 'mine', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ref_spectrum = compute_fft(ref_gray)\n",
    "    gsir_spectrum = compute_fft(gsir_gray)\n",
    "    tensoir_spectrum = compute_fft(tensoir_gray)\n",
    "    gtv_spectrum = compute_fft(gtv_gray)\n",
    "    mine_spectrum = compute_fft(mine_gray)\n",
    "\n",
    "    mse_0 = mse(ref_spectrum, ref_spectrum)\n",
    "    mse_1 = mse(ref_spectrum, gsir_spectrum)\n",
    "    mse_2 = mse(ref_spectrum, tensoir_spectrum)\n",
    "    mse_3 = mse(ref_spectrum, gtv_spectrum)\n",
    "    mse_4 = mse(ref_spectrum, mine_spectrum)\n",
    "\n",
    "    mse_0_lst = np.append(mse_0_lst, mse_0)\n",
    "    mse_1_lst = np.append(mse_1_lst, mse_1)\n",
    "    mse_2_lst = np.append(mse_2_lst, mse_2)\n",
    "    mse_3_lst = np.append(mse_3_lst, mse_3)\n",
    "    mse_4_lst = np.append(mse_4_lst, mse_4)\n",
    "\n",
    "print(f'Sanity Check: {mse_0_lst.mean()}')\n",
    "print('MSE between Reference and GS-IR:', mse_1_lst.mean())\n",
    "print('MSE between Reference and TensoIR:', mse_2_lst.mean())\n",
    "print('MSE between Reference and GTV:', mse_3_lst.mean())\n",
    "print('MSE between Reference and Mine:', mse_4_lst.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 1.0\n",
      "SSIM between Reference and GS-IR: 0.913605295248951\n",
      "SSIM between Reference and TensoIR: 0.914796172882652\n",
      "SSIM between Reference and GTV: 0.9031371764912148\n",
      "SSIM between Reference and Mine: 0.8974539038191308\n"
     ]
    }
   ],
   "source": [
    "ssim_score0_lst = np.array([])\n",
    "ssim_score1_lst = np.array([])\n",
    "ssim_score2_lst = np.array([])\n",
    "ssim_score3_lst = np.array([])\n",
    "ssim_score4_lst = np.array([])\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    # Load the images as RGB\n",
    "    ref = np.array(Image.open(os.path.join(imgs_dir, 'ref', f'r_{i}.png')).convert('RGB'))\n",
    "    gsir = np.array(Image.open(os.path.join(imgs_dir, 'gsir', f'r_{i}.png')).convert('RGB'))\n",
    "    tensoir = np.array(Image.open(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png')).convert('RGB'))\n",
    "    gtv = np.array(Image.open(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png')).convert('RGB'))\n",
    "    mine = np.array(Image.open(os.path.join(imgs_dir, 'mine', f'r_{i}.png')).convert('RGB'))\n",
    "\n",
    "    data_range = 255.0\n",
    "    ssim_score0, ssim_image0 = ssim(ref, ref, data_range=data_range, full=True, win_size=11, channel_axis=2)\n",
    "    ssim_score1, ssim_image1 = ssim(ref, gsir, data_range=data_range, full=True, win_size=11, channel_axis=2)\n",
    "    ssim_score2, ssim_image2 = ssim(ref, tensoir, data_range=data_range, full=True, win_size=11, channel_axis=2)\n",
    "    ssim_score3, ssim_image3 = ssim(ref, gtv, data_range=data_range, full=True, win_size=11, channel_axis=2)\n",
    "    ssim_score4, ssim_image4 = ssim(ref, mine, data_range=data_range, full=True, win_size=11, channel_axis=2)\n",
    "\n",
    "    ssim_score0_lst = np.append(ssim_score0_lst, ssim_score0)\n",
    "    ssim_score1_lst = np.append(ssim_score1_lst, ssim_score1)\n",
    "    ssim_score2_lst = np.append(ssim_score2_lst, ssim_score2)\n",
    "    ssim_score3_lst = np.append(ssim_score3_lst, ssim_score3)\n",
    "    ssim_score4_lst = np.append(ssim_score4_lst, ssim_score4)\n",
    "\n",
    "print(f'Sanity Check: {ssim_score0_lst.mean()}')\n",
    "print(f'SSIM between Reference and GS-IR: {ssim_score1_lst.mean()}')\n",
    "print(f'SSIM between Reference and TensoIR: {ssim_score2_lst.mean()}')\n",
    "print(f'SSIM between Reference and GTV: {ssim_score3_lst.mean()}')\n",
    "print(f'SSIM between Reference and Mine: {ssim_score4_lst.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 1.0\n",
      "SSIM between Reference and GS-IR: 0.9982483930688475\n",
      "SSIM between Reference and TensoIR: 0.9988099948507846\n",
      "SSIM between Reference and Mine: 0.9995848241336669\n",
      "SSIM between Reference and Mine: 0.998937512102088\n"
     ]
    }
   ],
   "source": [
    "ssim_score0_lst = np.array([])\n",
    "ssim_score1_lst = np.array([])\n",
    "ssim_score2_lst = np.array([])\n",
    "ssim_score3_lst = np.array([])\n",
    "ssim_score4_lst = np.array([])\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    # Load the images as grayscale\n",
    "    ref_gray = cv2.imread(os.path.join(imgs_dir, 'ref', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gsir_gray = cv2.imread(os.path.join(imgs_dir, 'gsir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    tensoir_gray = cv2.imread(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gtv_gray = cv2.imread(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    mine_gray = cv2.imread(os.path.join(imgs_dir, 'mine', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ref_spectrum = compute_fft(ref_gray)\n",
    "    gsir_spectrum = compute_fft(gsir_gray)\n",
    "    tensoir_spectrum = compute_fft(tensoir_gray)\n",
    "    gtv_spectrum = compute_fft(gtv_gray)\n",
    "    mine_spectrum = compute_fft(mine_gray)\n",
    "\n",
    "    # Compute SSIM\n",
    "    data_range_ref = ref_spectrum.max() - ref_spectrum.min()\n",
    "    data_range_gsir = gsir_spectrum.max() - gsir_spectrum.min()\n",
    "    data_range_tensoir = tensoir_spectrum.max() - tensoir_spectrum.min()\n",
    "    data_range_gtv = gtv_spectrum.max() - gtv_spectrum.min()\n",
    "    data_range_mine = mine_spectrum.max() - mine_spectrum.min()\n",
    "\n",
    "    ssim_score0, ssim_image0 = ssim(ref_spectrum, ref_spectrum, full=True, data_range=data_range_ref)\n",
    "    ssim_score1, ssim_image1 = ssim(ref_spectrum, gsir_spectrum, full=True, data_range=max(data_range_gsir, data_range_ref))\n",
    "    ssim_score2, ssim_image2 = ssim(ref_spectrum, tensoir_spectrum, full=True, data_range=max(data_range_tensoir, data_range_ref))\n",
    "    ssim_score3, ssim_image3 = ssim(ref_spectrum, gtv_spectrum, full=True, data_range=max(data_range_gtv, data_range_ref))\n",
    "    ssim_score4, ssim_image4 = ssim(ref_spectrum, mine_spectrum, full=True, data_range=max(data_range_mine, data_range_ref))\n",
    "\n",
    "    ssim_score0_lst = np.append(ssim_score0_lst, ssim_score0)\n",
    "    ssim_score1_lst = np.append(ssim_score1_lst, ssim_score1)\n",
    "    ssim_score2_lst = np.append(ssim_score2_lst, ssim_score2)\n",
    "    ssim_score3_lst = np.append(ssim_score3_lst, ssim_score3)\n",
    "    ssim_score4_lst = np.append(ssim_score4_lst, ssim_score4)\n",
    "\n",
    "print(f'Sanity Check: {ssim_score0_lst.mean()}')\n",
    "print('SSIM between Reference and GS-IR:', ssim_score1_lst.mean())\n",
    "print('SSIM between Reference and TensoIR:', ssim_score2.mean())\n",
    "print('SSIM between Reference and Mine:', ssim_score3.mean())\n",
    "print('SSIM between Reference and Mine:', ssim_score4.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulina/opt/anaconda3/lib/python3.9/site-packages/skimage/metrics/simple_metrics.py:163: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 10 * np.log10((data_range ** 2) / err)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: inf\n",
      "PSNR between Reference and GS-IR: 27.31194726812064\n",
      "PSNR between Reference and TensoIR: 27.883475167862233\n",
      "PSNR between Reference and GTV: 25.412697783204422\n",
      "PSNR between Reference and Mine: 25.225169787105393\n"
     ]
    }
   ],
   "source": [
    "psnr_score0_lst = np.array([])\n",
    "psnr_score1_lst = np.array([])\n",
    "psnr_score2_lst = np.array([])\n",
    "psnr_score3_lst = np.array([])\n",
    "psnr_score4_lst = np.array([])\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    # Load the images as RGB\n",
    "    ref = np.array(Image.open(os.path.join(imgs_dir, 'ref', f'r_{i}.png')).convert('RGB'))\n",
    "    gsir = np.array(Image.open(os.path.join(imgs_dir, 'gsir', f'r_{i}.png')).convert('RGB'))\n",
    "    tensoir = np.array(Image.open(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png')).convert('RGB'))\n",
    "    gtv = np.array(Image.open(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png')).convert('RGB'))\n",
    "    mine = np.array(Image.open(os.path.join(imgs_dir, 'mine', f'r_{i}.png')).convert('RGB'))\n",
    "\n",
    "    data_range = 255.0\n",
    "    psnr_score0 = psnr(ref, ref, data_range=data_range)\n",
    "    psnr_score1 = psnr(ref, gsir, data_range=data_range)\n",
    "    psnr_score2 = psnr(ref, tensoir, data_range=data_range)\n",
    "    psnr_score3 = psnr(ref, gtv, data_range=data_range)\n",
    "    psnr_score4 = psnr(ref, mine, data_range=data_range)\n",
    "\n",
    "    psnr_score0_lst = np.append(psnr_score0_lst, psnr_score0)\n",
    "    psnr_score1_lst = np.append(psnr_score1_lst, psnr_score1)\n",
    "    psnr_score2_lst = np.append(psnr_score2_lst, psnr_score2)\n",
    "    psnr_score3_lst = np.append(psnr_score3_lst, psnr_score3)\n",
    "    psnr_score4_lst = np.append(psnr_score4_lst, psnr_score4)\n",
    "\n",
    "print(f'Sanity Check: {psnr_score0_lst.mean()}')\n",
    "print(f'PSNR between Reference and GS-IR: {psnr_score1_lst.mean()}')\n",
    "print(f'PSNR between Reference and TensoIR: {psnr_score2_lst.mean()}')\n",
    "print(f'PSNR between Reference and GTV: {psnr_score3_lst.mean()}')\n",
    "print(f'PSNR between Reference and Mine: {psnr_score4_lst.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: inf\n",
      "PSNR between Reference and GS-IR: 64.72241492603902\n",
      "PSNR between Reference and TensoIR: 65.81585578852078\n",
      "PSNR between Reference and GTV: 66.15547068157515\n",
      "PSNR between Reference and Mine: 64.55433119670506\n"
     ]
    }
   ],
   "source": [
    "psnr_score0_lst = np.array([])\n",
    "psnr_score1_lst = np.array([])\n",
    "psnr_score2_lst = np.array([])\n",
    "psnr_score3_lst = np.array([])\n",
    "psnr_score4_lst = np.array([])\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    # Load the images as grayscale\n",
    "    ref_gray = cv2.imread(os.path.join(imgs_dir, 'ref', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gsir_gray = cv2.imread(os.path.join(imgs_dir, 'gsir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    tensoir_gray = cv2.imread(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gtv_gray = cv2.imread(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    mine_gray = cv2.imread(os.path.join(imgs_dir, 'mine', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ref_spectrum = compute_fft(ref_gray)\n",
    "    gsir_spectrum = compute_fft(gsir_gray)\n",
    "    tensoir_spectrum = compute_fft(tensoir_gray)\n",
    "    gtv_spectrum = compute_fft(gtv_gray)\n",
    "    mine_spectrum = compute_fft(mine_gray)\n",
    "\n",
    "    data_range_ref = ref_spectrum.max() - ref_spectrum.min()\n",
    "    data_range_gsir = gsir_spectrum.max() - gsir_spectrum.min()\n",
    "    data_range_tensoir = tensoir_spectrum.max() - tensoir_spectrum.min()\n",
    "    data_range_gtv = gtv_spectrum.max() - gtv_spectrum.min()\n",
    "    data_range_mine = mine_spectrum.max() - mine_spectrum.min()\n",
    "\n",
    "    psnr_value0 = psnr(ref_spectrum, ref_spectrum, data_range=data_range_ref)\n",
    "    psnr_value1 = psnr(ref_spectrum, gsir_spectrum, data_range=max(data_range_gsir, data_range_ref))\n",
    "    psnr_value2 = psnr(ref_spectrum, tensoir_spectrum, data_range=max(data_range_tensoir, data_range_ref))\n",
    "    psnr_value3 = psnr(ref_spectrum, gtv_spectrum, data_range=max(data_range_gtv, data_range_ref))\n",
    "    psnr_value4 = psnr(ref_spectrum, mine_spectrum, data_range=max(data_range_mine, data_range_ref))\n",
    "\n",
    "    psnr_score0_lst = np.append(psnr_score0_lst, psnr_value0)\n",
    "    psnr_score1_lst = np.append(psnr_score1_lst, psnr_value1)\n",
    "    psnr_score2_lst = np.append(psnr_score2_lst, psnr_value2)\n",
    "    psnr_score3_lst = np.append(psnr_score3_lst, psnr_value3)\n",
    "    psnr_score4_lst = np.append(psnr_score4_lst, psnr_value4)\n",
    "\n",
    "print(f'Sanity Check: {psnr_score0_lst.mean()}')\n",
    "print('PSNR between Reference and GS-IR:', psnr_score1_lst.mean())\n",
    "print('PSNR between Reference and TensoIR:', psnr_score2_lst.mean())\n",
    "print('PSNR between Reference and GTV:', psnr_score3_lst.mean())\n",
    "print('PSNR between Reference and Mine:', psnr_score4_lst.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LPIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulina/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/paulina/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/paulina/opt/anaconda3/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulina/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /Users/paulina/opt/anaconda3/lib/python3.9/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [squeeze], v[0.1], spatial [off]\n",
      "Loading model from: /Users/paulina/opt/anaconda3/lib/python3.9/site-packages/lpips/weights/v0.1/squeeze.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulina/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize LPIPS model\n",
    "# You can use 'alex', 'vgg', or 'squeeze'\n",
    "lpips_model_alex = lpips.LPIPS(net='alex') \n",
    "lpips_model_vgg = lpips.LPIPS(net='vgg') \n",
    "lpips_model_squeeze = lpips.LPIPS(net='squeeze') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_rgb_for_lpips(image):\n",
    "    # Normalise the image to the range [-1, 1], as expected by LPIPS\n",
    "    return (2 * (image / 255.0) - 1.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0...\n",
      "Processing image 1...\n",
      "Processing image 2...\n",
      "Processing image 3...\n",
      "Processing image 4...\n",
      "Processing image 5...\n",
      "Processing image 6...\n",
      "Processing image 7...\n",
      "Processing image 8...\n",
      "Processing image 9...\n",
      "Processing image 10...\n",
      "Processing image 11...\n",
      "Processing image 12...\n",
      "Processing image 13...\n",
      "Processing image 14...\n",
      "Processing image 15...\n",
      "Processing image 16...\n",
      "Processing image 17...\n",
      "Processing image 18...\n",
      "Processing image 19...\n",
      "Processing image 20...\n",
      "Processing image 21...\n",
      "Processing image 22...\n",
      "Processing image 23...\n",
      "Processing image 24...\n",
      "Processing image 25...\n",
      "Processing image 26...\n",
      "Processing image 27...\n",
      "Processing image 28...\n",
      "Processing image 29...\n",
      "Processing image 30...\n",
      "Processing image 31...\n",
      "Processing image 32...\n",
      "Processing image 33...\n",
      "Processing image 34...\n",
      "Processing image 35...\n",
      "Processing image 36...\n",
      "Processing image 37...\n",
      "Processing image 38...\n",
      "Processing image 39...\n",
      "Processing image 40...\n",
      "Processing image 41...\n",
      "Processing image 42...\n",
      "Processing image 43...\n",
      "Processing image 44...\n",
      "Processing image 45...\n",
      "Processing image 46...\n",
      "Processing image 47...\n",
      "Processing image 48...\n",
      "Processing image 49...\n",
      "Processing image 50...\n",
      "Processing image 51...\n",
      "Processing image 52...\n",
      "Processing image 53...\n",
      "Processing image 54...\n",
      "Processing image 55...\n",
      "Processing image 56...\n",
      "Processing image 57...\n",
      "Processing image 58...\n",
      "Processing image 59...\n",
      "Processing image 60...\n",
      "Processing image 61...\n",
      "Processing image 62...\n",
      "Processing image 63...\n",
      "Processing image 64...\n",
      "Processing image 65...\n",
      "Processing image 66...\n",
      "Processing image 67...\n",
      "Processing image 68...\n",
      "Processing image 69...\n",
      "Processing image 70...\n",
      "Processing image 71...\n",
      "Processing image 72...\n",
      "Processing image 73...\n",
      "Processing image 74...\n",
      "Processing image 75...\n",
      "Processing image 76...\n",
      "Processing image 77...\n",
      "Processing image 78...\n",
      "Processing image 79...\n",
      "Processing image 80...\n",
      "Processing image 81...\n",
      "Processing image 82...\n",
      "Processing image 83...\n",
      "Processing image 84...\n",
      "Processing image 85...\n",
      "Processing image 86...\n",
      "Processing image 87...\n",
      "Processing image 88...\n",
      "Processing image 89...\n",
      "Processing image 90...\n",
      "Processing image 91...\n",
      "Processing image 92...\n",
      "Processing image 93...\n",
      "Processing image 94...\n",
      "Processing image 95...\n",
      "Processing image 96...\n",
      "Processing image 97...\n",
      "Processing image 98...\n",
      "Processing image 99...\n",
      "Processing image 100...\n",
      "Processing image 101...\n",
      "Processing image 102...\n",
      "Processing image 103...\n",
      "Processing image 104...\n",
      "Processing image 105...\n",
      "Processing image 106...\n",
      "Processing image 107...\n",
      "Processing image 108...\n",
      "Processing image 109...\n",
      "Processing image 110...\n",
      "Processing image 111...\n",
      "Processing image 112...\n",
      "Processing image 113...\n",
      "Processing image 114...\n",
      "Processing image 115...\n",
      "Processing image 116...\n",
      "Processing image 117...\n",
      "Processing image 118...\n",
      "Processing image 119...\n",
      "Processing image 120...\n",
      "Processing image 121...\n",
      "Processing image 122...\n",
      "Processing image 123...\n",
      "Processing image 124...\n",
      "Processing image 125...\n",
      "Processing image 126...\n",
      "Processing image 127...\n",
      "Processing image 128...\n",
      "Processing image 129...\n",
      "Processing image 130...\n",
      "Processing image 131...\n",
      "Processing image 132...\n",
      "Processing image 133...\n",
      "Processing image 134...\n",
      "Processing image 135...\n",
      "Processing image 136...\n",
      "Processing image 137...\n",
      "Processing image 138...\n",
      "Processing image 139...\n",
      "Processing image 140...\n",
      "Processing image 141...\n",
      "Processing image 142...\n",
      "Processing image 143...\n",
      "Processing image 144...\n",
      "Processing image 145...\n",
      "Processing image 146...\n",
      "Processing image 147...\n",
      "Processing image 148...\n",
      "Processing image 149...\n",
      "Processing image 150...\n",
      "Processing image 151...\n",
      "Processing image 152...\n",
      "Processing image 153...\n",
      "Processing image 154...\n",
      "Processing image 155...\n",
      "Processing image 156...\n",
      "Processing image 157...\n",
      "Processing image 158...\n",
      "Processing image 159...\n",
      "Processing image 160...\n",
      "Processing image 161...\n",
      "Processing image 162...\n",
      "Processing image 163...\n",
      "Processing image 164...\n",
      "Processing image 165...\n",
      "Processing image 166...\n",
      "Processing image 167...\n",
      "Processing image 168...\n",
      "Processing image 169...\n",
      "Processing image 170...\n",
      "Processing image 171...\n",
      "Processing image 172...\n",
      "Processing image 173...\n",
      "Processing image 174...\n",
      "Processing image 175...\n",
      "Processing image 176...\n",
      "Processing image 177...\n",
      "Processing image 178...\n",
      "Processing image 179...\n",
      "Processing image 180...\n",
      "Processing image 181...\n",
      "Processing image 182...\n",
      "Processing image 183...\n",
      "Processing image 184...\n",
      "Processing image 185...\n",
      "Processing image 186...\n",
      "Processing image 187...\n",
      "Processing image 188...\n",
      "Processing image 189...\n",
      "Processing image 190...\n",
      "Processing image 191...\n",
      "Processing image 192...\n",
      "Processing image 193...\n",
      "Processing image 194...\n",
      "Processing image 195...\n",
      "Processing image 196...\n",
      "Processing image 197...\n",
      "Processing image 198...\n",
      "Processing image 199...\n"
     ]
    }
   ],
   "source": [
    "ref_imgs_rgb = []\n",
    "gsir_imgs_rgb = []\n",
    "tensoir_imgs_rgb = []\n",
    "gtv_imgs_rgb = []\n",
    "mine_imgs_rgb = []\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    print(f'Processing image {i}...')\n",
    "    # Load the images as RGB\n",
    "    ref = np.array(Image.open(os.path.join(imgs_dir, 'ref', f'r_{i}.png')).convert('RGB'))\n",
    "    gsir = np.array(Image.open(os.path.join(imgs_dir, 'gsir', f'r_{i}.png')).convert('RGB'))\n",
    "    tensoir = np.array(Image.open(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png')).convert('RGB'))\n",
    "    gtv = np.array(Image.open(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png')).convert('RGB'))\n",
    "    mine = np.array(Image.open(os.path.join(imgs_dir, 'mine', f'r_{i}.png')).convert('RGB'))\n",
    "\n",
    "    ref_tensor = torch.from_numpy(normalise_rgb_for_lpips(ref)).permute(2, 0, 1).unsqueeze(0)\n",
    "    gsir_tensor = torch.from_numpy(normalise_rgb_for_lpips(gsir)).permute(2, 0, 1).unsqueeze(0)\n",
    "    tensoir_tensor = torch.from_numpy(normalise_rgb_for_lpips(tensoir)).permute(2, 0, 1).unsqueeze(0)\n",
    "    gtv_tensor = torch.from_numpy(normalise_rgb_for_lpips(gtv)).permute(2, 0, 1).unsqueeze(0)\n",
    "    mine_tensor = torch.from_numpy(normalise_rgb_for_lpips(mine)).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    ref_imgs_rgb.append(ref_tensor)\n",
    "    gsir_imgs_rgb.append(gsir_tensor)\n",
    "    tensoir_imgs_rgb.append(tensoir_tensor)\n",
    "    gtv_imgs_rgb.append(gtv_tensor)\n",
    "    mine_imgs_rgb.append(mine_tensor)\n",
    "\n",
    "ref_imgs_rgb = torch.cat(ref_imgs_rgb, dim=0)\n",
    "gsir_imgs_rgb = torch.cat(gsir_imgs_rgb, dim=0)\n",
    "tensoir_imgs_rgb = torch.cat(tensoir_imgs_rgb, dim=0)\n",
    "gtv_imgs_rgb = torch.cat(gtv_imgs_rgb, dim=0)\n",
    "mine_imgs_rgb = torch.cat(mine_imgs_rgb, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LPIPS\n",
    "lpips_alex_score0_rgb = lpips_model_alex(ref_imgs_rgb, ref_imgs_rgb)\n",
    "lpips_alex_score1_rgb = lpips_model_alex(ref_imgs_rgb, gsir_imgs_rgb)\n",
    "lpips_alex_score2_rgb = lpips_model_alex(ref_imgs_rgb, tensoir_imgs_rgb)\n",
    "lpips_alex_score3_rgb = lpips_model_alex(ref_imgs_rgb, gtv_imgs_rgb)\n",
    "lpips_alex_score4_rgb = lpips_model_alex(ref_imgs_rgb, mine_imgs_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "LPIPS distance between Reference and GS-IR: tensor(0.0805, grad_fn=<MeanBackward0>)\n",
      "LPIPS distance between Reference and TensoIR: tensor(0.0783, grad_fn=<MeanBackward0>)\n",
      "LPIPS distance between Reference and GTV: tensor(0.0315, grad_fn=<MeanBackward0>)\n",
      "LPIPS distance between Reference and Mine: tensor(0.0862, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lpips_alex_score0_rgb_mean = torch.mean(lpips_alex_score0_rgb)\n",
    "lpips_alex_score1_rgb_mean = torch.mean(lpips_alex_score1_rgb)\n",
    "lpips_alex_score2_rgb_mean = torch.mean(lpips_alex_score2_rgb)\n",
    "lpips_alex_score3_rgb_mean = torch.mean(lpips_alex_score3_rgb)\n",
    "lpips_alex_score4_rgb_mean = torch.mean(lpips_alex_score4_rgb)\n",
    "\n",
    "print(f'Sanity Check: {lpips_alex_score0_rgb_mean}')\n",
    "print('LPIPS distance between Reference and GS-IR:', lpips_alex_score1_rgb_mean)\n",
    "print('LPIPS distance between Reference and TensoIR:', lpips_alex_score2_rgb_mean)\n",
    "print('LPIPS distance between Reference and GTV:', lpips_alex_score3_rgb_mean)\n",
    "print('LPIPS distance between Reference and Mine:', lpips_alex_score4_rgb_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_rgb_score_vgg = []\n",
    "gsir_rgb_score_vgg = []\n",
    "tensoir_rgb_score_vgg = []\n",
    "gtv_rgb_score_vgg = []\n",
    "mine_rgb_score_vgg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images 0 to 10...\n",
      "Processing images 10 to 20...\n",
      "Processing images 20 to 30...\n",
      "Processing images 30 to 40...\n",
      "Processing images 40 to 50...\n",
      "Processing images 50 to 60...\n",
      "Processing images 60 to 70...\n",
      "Processing images 70 to 80...\n",
      "Processing images 80 to 90...\n",
      "Processing images 90 to 100...\n",
      "Processing images 100 to 110...\n",
      "Processing images 110 to 120...\n",
      "Processing images 120 to 130...\n",
      "Processing images 130 to 140...\n",
      "Processing images 140 to 150...\n",
      "Processing images 150 to 160...\n",
      "Processing images 160 to 170...\n",
      "Processing images 170 to 180...\n",
      "Processing images 180 to 190...\n",
      "Processing images 190 to 200...\n"
     ]
    }
   ],
   "source": [
    "interval = 10\n",
    "for i in range(0, number_of_imgs, interval):\n",
    "    print(f'Processing images {i} to {i+interval}...')\n",
    "    sub_batch_ref = ref_imgs_rgb[i:i+interval]\n",
    "    sub_batch_gsir = gsir_imgs_rgb[i:i+interval]\n",
    "    sub_batch_tensoir = tensoir_imgs_rgb[i:i+interval]\n",
    "    sub_batch_gtv = gtv_imgs_rgb[i:i+interval]\n",
    "    sub_batch_mine = mine_imgs_rgb[i:i+interval]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lpips_vgg_score0 = lpips_model_vgg(sub_batch_ref, sub_batch_ref)\n",
    "        lpips_vgg_score1 = lpips_model_vgg(sub_batch_ref, sub_batch_gsir)\n",
    "        lpips_vgg_score2 = lpips_model_vgg(sub_batch_ref, sub_batch_tensoir)\n",
    "        lpips_vgg_score3 = lpips_model_vgg(sub_batch_ref, sub_batch_gtv)\n",
    "        lpips_vgg_score4 = lpips_model_vgg(sub_batch_ref, sub_batch_mine)\n",
    "\n",
    "    ref_rgb_score_vgg.append(lpips_vgg_score0)\n",
    "    gsir_rgb_score_vgg.append(lpips_vgg_score1)\n",
    "    tensoir_rgb_score_vgg.append(lpips_vgg_score2)\n",
    "    gtv_rgb_score_vgg.append(lpips_vgg_score3)\n",
    "    mine_rgb_score_vgg.append(lpips_vgg_score4)\n",
    "\n",
    "ref_rgb_score_vgg = torch.cat(ref_rgb_score_vgg).squeeze()\n",
    "gsir_rgb_score_vgg = torch.cat(gsir_rgb_score_vgg).squeeze()\n",
    "tensoir_rgb_score_vgg = torch.cat(tensoir_rgb_score_vgg).squeeze()\n",
    "gtv_rgb_score_vgg = torch.cat(gtv_rgb_score_vgg).squeeze()\n",
    "mine_rgb_score_vgg = torch.cat(mine_rgb_score_vgg).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "LPIPS distance between Reference and GS-IR: tensor(0.0737)\n",
      "LPIPS distance between Reference and TensoIR: tensor(0.0733)\n",
      "LPIPS distance between Reference and GTV: tensor(0.0427)\n",
      "LPIPS distance between Reference and Mine: tensor(0.0649)\n"
     ]
    }
   ],
   "source": [
    "lpips_vgg_score0_rgb_mean = torch.mean(ref_rgb_score_vgg)\n",
    "lpips_vgg_score1_rgb_mean = torch.mean(gsir_rgb_score_vgg)\n",
    "lpips_vgg_score2_rgb_mean = torch.mean(tensoir_rgb_score_vgg)\n",
    "lpips_vgg_score3_rgb_mean = torch.mean(gtv_rgb_score_vgg)\n",
    "lpips_vgg_score4_rgb_mean = torch.mean(mine_rgb_score_vgg)\n",
    "\n",
    "print(f'Sanity Check: {lpips_vgg_score0_rgb_mean}')\n",
    "print('LPIPS distance between Reference and GS-IR:', lpips_vgg_score1_rgb_mean)\n",
    "print('LPIPS distance between Reference and TensoIR:', lpips_vgg_score2_rgb_mean)\n",
    "print('LPIPS distance between Reference and GTV:', lpips_vgg_score3_rgb_mean)\n",
    "print('LPIPS distance between Reference and Mine:', lpips_vgg_score4_rgb_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_rgb_score_squeeze = []\n",
    "gsir_rgb_score_squeeze = []\n",
    "tensoir_rgb_score_squeeze = []\n",
    "gtv_rgb_score_squeeze = []\n",
    "mine_rgb_score_squeeze = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images 0 to 10...\n",
      "Processing images 10 to 20...\n",
      "Processing images 20 to 30...\n",
      "Processing images 30 to 40...\n",
      "Processing images 40 to 50...\n",
      "Processing images 50 to 60...\n",
      "Processing images 60 to 70...\n",
      "Processing images 70 to 80...\n",
      "Processing images 80 to 90...\n",
      "Processing images 90 to 100...\n",
      "Processing images 100 to 110...\n",
      "Processing images 110 to 120...\n",
      "Processing images 120 to 130...\n",
      "Processing images 130 to 140...\n",
      "Processing images 140 to 150...\n",
      "Processing images 150 to 160...\n",
      "Processing images 160 to 170...\n",
      "Processing images 170 to 180...\n",
      "Processing images 180 to 190...\n",
      "Processing images 190 to 200...\n"
     ]
    }
   ],
   "source": [
    "interval = 10\n",
    "for i in range(0, number_of_imgs, interval):\n",
    "    print(f'Processing images {i} to {i+interval}...')\n",
    "    sub_batch_ref = ref_imgs_rgb[i:i+interval]\n",
    "    sub_batch_gsir = gsir_imgs_rgb[i:i+interval]\n",
    "    sub_batch_tensoir = tensoir_imgs_rgb[i:i+interval]\n",
    "    sub_batch_gtv = gtv_imgs_rgb[i:i+interval]\n",
    "    sub_batch_mine = mine_imgs_rgb[i:i+interval]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lpips_squeeze_score0 = lpips_model_squeeze(sub_batch_ref, sub_batch_ref)\n",
    "        lpips_squeeze_score1 = lpips_model_squeeze(sub_batch_ref, sub_batch_gsir)\n",
    "        lpips_squeeze_score2 = lpips_model_squeeze(sub_batch_ref, sub_batch_tensoir)\n",
    "        lpips_squeeze_score3 = lpips_model_squeeze(sub_batch_ref, sub_batch_gtv)\n",
    "        lpips_squeeze_score4 = lpips_model_squeeze(sub_batch_ref, sub_batch_mine)\n",
    "\n",
    "    ref_rgb_score_squeeze.append(lpips_squeeze_score0)\n",
    "    gsir_rgb_score_squeeze.append(lpips_squeeze_score1)\n",
    "    tensoir_rgb_score_squeeze.append(lpips_squeeze_score2)\n",
    "    gtv_rgb_score_squeeze.append(lpips_squeeze_score3)\n",
    "    mine_rgb_score_squeeze.append(lpips_squeeze_score4)\n",
    "\n",
    "ref_rgb_score_squeeze = torch.cat(ref_rgb_score_squeeze).squeeze()\n",
    "gsir_rgb_score_squeeze = torch.cat(gsir_rgb_score_squeeze).squeeze()\n",
    "tensoir_rgb_score_squeeze = torch.cat(tensoir_rgb_score_squeeze).squeeze()\n",
    "gtv_rgb_score_squeeze = torch.cat(gtv_rgb_score_squeeze).squeeze()\n",
    "mine_rgb_score_squeeze = torch.cat(mine_rgb_score_squeeze).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "LPIPS distance between Reference and GS-IR: tensor(0.0480)\n",
      "LPIPS distance between Reference and TensoIR: tensor(0.0525)\n",
      "LPIPS distance between Reference and GTV: tensor(0.0181)\n",
      "LPIPS distance between Reference and Mine: tensor(0.0319)\n"
     ]
    }
   ],
   "source": [
    "lpips_squeeze_score0_rgb_mean = torch.mean(ref_rgb_score_squeeze)\n",
    "lpips_squeeze_score1_rgb_mean = torch.mean(gsir_rgb_score_squeeze)\n",
    "lpips_squeeze_score2_rgb_mean = torch.mean(tensoir_rgb_score_squeeze)\n",
    "lpips_squeeze_score3_rgb_mean = torch.mean(gtv_rgb_score_squeeze)\n",
    "lpips_squeeze_score4_rgb_mean = torch.mean(mine_rgb_score_squeeze)\n",
    "\n",
    "print(f'Sanity Check: {lpips_squeeze_score0_rgb_mean}')\n",
    "print('LPIPS distance between Reference and GS-IR:', lpips_squeeze_score1_rgb_mean)\n",
    "print('LPIPS distance between Reference and TensoIR:', lpips_squeeze_score2_rgb_mean)\n",
    "print('LPIPS distance between Reference and GTV:', lpips_squeeze_score3_rgb_mean)\n",
    "print('LPIPS distance between Reference and Mine:', lpips_squeeze_score4_rgb_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_fourier_for_lpips(image):\n",
    "    # Normalise the image to the range [-1, 1], as expected by LPIPS\n",
    "    img_max = image.max()\n",
    "    img_min = image.min()\n",
    "    return (2 * ((image - img_min) / (img_max - img_min)) - 1).astype(np.float32)\n",
    "\n",
    "def make_rgb_from_grayscale(image):\n",
    "    # Convert the grayscale image to RGB\n",
    "    return np.stack((image,) * 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0...\n",
      "Processing image 1...\n",
      "Processing image 2...\n",
      "Processing image 3...\n",
      "Processing image 4...\n",
      "Processing image 5...\n",
      "Processing image 6...\n",
      "Processing image 7...\n",
      "Processing image 8...\n",
      "Processing image 9...\n",
      "Processing image 10...\n",
      "Processing image 11...\n",
      "Processing image 12...\n",
      "Processing image 13...\n",
      "Processing image 14...\n",
      "Processing image 15...\n",
      "Processing image 16...\n",
      "Processing image 17...\n",
      "Processing image 18...\n",
      "Processing image 19...\n",
      "Processing image 20...\n",
      "Processing image 21...\n",
      "Processing image 22...\n",
      "Processing image 23...\n",
      "Processing image 24...\n",
      "Processing image 25...\n",
      "Processing image 26...\n",
      "Processing image 27...\n",
      "Processing image 28...\n",
      "Processing image 29...\n",
      "Processing image 30...\n",
      "Processing image 31...\n",
      "Processing image 32...\n",
      "Processing image 33...\n",
      "Processing image 34...\n",
      "Processing image 35...\n",
      "Processing image 36...\n",
      "Processing image 37...\n",
      "Processing image 38...\n",
      "Processing image 39...\n",
      "Processing image 40...\n",
      "Processing image 41...\n",
      "Processing image 42...\n",
      "Processing image 43...\n",
      "Processing image 44...\n",
      "Processing image 45...\n",
      "Processing image 46...\n",
      "Processing image 47...\n",
      "Processing image 48...\n",
      "Processing image 49...\n",
      "Processing image 50...\n",
      "Processing image 51...\n",
      "Processing image 52...\n",
      "Processing image 53...\n",
      "Processing image 54...\n",
      "Processing image 55...\n",
      "Processing image 56...\n",
      "Processing image 57...\n",
      "Processing image 58...\n",
      "Processing image 59...\n",
      "Processing image 60...\n",
      "Processing image 61...\n",
      "Processing image 62...\n",
      "Processing image 63...\n",
      "Processing image 64...\n",
      "Processing image 65...\n",
      "Processing image 66...\n",
      "Processing image 67...\n",
      "Processing image 68...\n",
      "Processing image 69...\n",
      "Processing image 70...\n",
      "Processing image 71...\n",
      "Processing image 72...\n",
      "Processing image 73...\n",
      "Processing image 74...\n",
      "Processing image 75...\n",
      "Processing image 76...\n",
      "Processing image 77...\n",
      "Processing image 78...\n",
      "Processing image 79...\n",
      "Processing image 80...\n",
      "Processing image 81...\n",
      "Processing image 82...\n",
      "Processing image 83...\n",
      "Processing image 84...\n",
      "Processing image 85...\n",
      "Processing image 86...\n",
      "Processing image 87...\n",
      "Processing image 88...\n",
      "Processing image 89...\n",
      "Processing image 90...\n",
      "Processing image 91...\n",
      "Processing image 92...\n",
      "Processing image 93...\n",
      "Processing image 94...\n",
      "Processing image 95...\n",
      "Processing image 96...\n",
      "Processing image 97...\n",
      "Processing image 98...\n",
      "Processing image 99...\n",
      "Processing image 100...\n",
      "Processing image 101...\n",
      "Processing image 102...\n",
      "Processing image 103...\n",
      "Processing image 104...\n",
      "Processing image 105...\n",
      "Processing image 106...\n",
      "Processing image 107...\n",
      "Processing image 108...\n",
      "Processing image 109...\n",
      "Processing image 110...\n",
      "Processing image 111...\n",
      "Processing image 112...\n",
      "Processing image 113...\n",
      "Processing image 114...\n",
      "Processing image 115...\n",
      "Processing image 116...\n",
      "Processing image 117...\n",
      "Processing image 118...\n",
      "Processing image 119...\n",
      "Processing image 120...\n",
      "Processing image 121...\n",
      "Processing image 122...\n",
      "Processing image 123...\n",
      "Processing image 124...\n",
      "Processing image 125...\n",
      "Processing image 126...\n",
      "Processing image 127...\n",
      "Processing image 128...\n",
      "Processing image 129...\n",
      "Processing image 130...\n",
      "Processing image 131...\n",
      "Processing image 132...\n",
      "Processing image 133...\n",
      "Processing image 134...\n",
      "Processing image 135...\n",
      "Processing image 136...\n",
      "Processing image 137...\n",
      "Processing image 138...\n",
      "Processing image 139...\n",
      "Processing image 140...\n",
      "Processing image 141...\n",
      "Processing image 142...\n",
      "Processing image 143...\n",
      "Processing image 144...\n",
      "Processing image 145...\n",
      "Processing image 146...\n",
      "Processing image 147...\n",
      "Processing image 148...\n",
      "Processing image 149...\n",
      "Processing image 150...\n",
      "Processing image 151...\n",
      "Processing image 152...\n",
      "Processing image 153...\n",
      "Processing image 154...\n",
      "Processing image 155...\n",
      "Processing image 156...\n",
      "Processing image 157...\n",
      "Processing image 158...\n",
      "Processing image 159...\n",
      "Processing image 160...\n",
      "Processing image 161...\n",
      "Processing image 162...\n",
      "Processing image 163...\n",
      "Processing image 164...\n",
      "Processing image 165...\n",
      "Processing image 166...\n",
      "Processing image 167...\n",
      "Processing image 168...\n",
      "Processing image 169...\n",
      "Processing image 170...\n",
      "Processing image 171...\n",
      "Processing image 172...\n",
      "Processing image 173...\n",
      "Processing image 174...\n",
      "Processing image 175...\n",
      "Processing image 176...\n",
      "Processing image 177...\n",
      "Processing image 178...\n",
      "Processing image 179...\n",
      "Processing image 180...\n",
      "Processing image 181...\n",
      "Processing image 182...\n",
      "Processing image 183...\n",
      "Processing image 184...\n",
      "Processing image 185...\n",
      "Processing image 186...\n",
      "Processing image 187...\n",
      "Processing image 188...\n",
      "Processing image 189...\n",
      "Processing image 190...\n",
      "Processing image 191...\n",
      "Processing image 192...\n",
      "Processing image 193...\n",
      "Processing image 194...\n",
      "Processing image 195...\n",
      "Processing image 196...\n",
      "Processing image 197...\n",
      "Processing image 198...\n",
      "Processing image 199...\n"
     ]
    }
   ],
   "source": [
    "ref_imgs_fourier = []\n",
    "gsir_imgs_fourier = []\n",
    "tensoir_imgs_fourier = []\n",
    "gtv_imgs_fourier = []\n",
    "mine_imgs_fourier = []\n",
    "\n",
    "for i in range(number_of_imgs):\n",
    "    print(f'Processing image {i}...')\n",
    "    # Load the images as grayscale\n",
    "    ref_gray = cv2.imread(os.path.join(imgs_dir, 'ref', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gsir_gray = cv2.imread(os.path.join(imgs_dir, 'gsir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    tensoir_gray = cv2.imread(os.path.join(imgs_dir, 'tensoir', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    gtv_gray = cv2.imread(os.path.join(imgs_dir, 'mine_gt', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "    mine_gray = cv2.imread(os.path.join(imgs_dir, 'mine', f'r_{i}.png'), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ref_spectrum = make_rgb_from_grayscale(normalise_fourier_for_lpips(compute_fft(ref_gray)))\n",
    "    gsir_spectrum = make_rgb_from_grayscale(normalise_fourier_for_lpips(compute_fft(gsir_gray)))\n",
    "    tensoir_spectrum = make_rgb_from_grayscale(normalise_fourier_for_lpips(compute_fft(tensoir_gray)))\n",
    "    gtv_spectrum = make_rgb_from_grayscale(normalise_fourier_for_lpips(compute_fft(gtv_gray)))\n",
    "    mine_spectrum = make_rgb_from_grayscale(normalise_fourier_for_lpips(compute_fft(mine_gray)))\n",
    "\n",
    "    ref_spectrum_tensor = torch.from_numpy(ref_spectrum).permute(2, 0, 1).unsqueeze(0)\n",
    "    gsir_spectrum_tensor = torch.from_numpy(gsir_spectrum).permute(2, 0, 1).unsqueeze(0)\n",
    "    tensoir_spectrum_tensor = torch.from_numpy(tensoir_spectrum).permute(2, 0, 1).unsqueeze(0)\n",
    "    gtv_spectrum_tensor = torch.from_numpy(gtv_spectrum).permute(2, 0, 1).unsqueeze(0)\n",
    "    mine_spectrum_tensor = torch.from_numpy(mine_spectrum).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    ref_imgs_fourier.append(ref_spectrum_tensor)\n",
    "    gsir_imgs_fourier.append(gsir_spectrum_tensor)\n",
    "    tensoir_imgs_fourier.append(tensoir_spectrum_tensor)\n",
    "    gtv_imgs_fourier.append(gtv_spectrum_tensor)\n",
    "    mine_imgs_fourier.append(mine_spectrum_tensor)\n",
    "\n",
    "ref_imgs_fourier = torch.cat(ref_imgs_fourier, dim=0)\n",
    "gsir_imgs_fourier = torch.cat(gsir_imgs_fourier, dim=0)\n",
    "tensoir_imgs_fourier = torch.cat(tensoir_imgs_fourier, dim=0)\n",
    "gtv_imgs_fourier = torch.cat(gtv_imgs_fourier, dim=0)\n",
    "mine_imgs_fourier = torch.cat(mine_imgs_fourier, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpips_alex_score0_fourier = lpips_model_alex(ref_imgs_fourier, ref_imgs_fourier)\n",
    "lpips_alex_score1_fourier = lpips_model_alex(ref_imgs_fourier, gsir_imgs_fourier)\n",
    "lpips_alex_score2_fourier = lpips_model_alex(ref_imgs_fourier, tensoir_imgs_fourier)\n",
    "lpips_alex_score3_fourier = lpips_model_alex(ref_imgs_fourier, gtv_imgs_fourier)\n",
    "lpips_alex_score4_fourier = lpips_model_alex(ref_imgs_fourier, mine_imgs_fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "LPIPS distance between Reference and GS-IR: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "LPIPS distance between Reference and TensoIR: tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "LPIPS distance between Reference and GtV: tensor(2.7474e-05, grad_fn=<MeanBackward0>)\n",
      "LPIPS distance between Reference and Mine: tensor(0.0001, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lpips_alex_score0_fourier_mean = torch.mean(lpips_alex_score0_fourier)\n",
    "lpips_alex_score1_fourier_mean = torch.mean(lpips_alex_score1_fourier)\n",
    "lpips_alex_score2_fourier_mean = torch.mean(lpips_alex_score2_fourier)\n",
    "lpips_alex_score3_fourier_mean = torch.mean(lpips_alex_score3_fourier)\n",
    "lpips_alex_score4_fourier_mean = torch.mean(lpips_alex_score4_fourier)\n",
    "\n",
    "print(f'Sanity Check: {lpips_alex_score0_fourier_mean}')\n",
    "print('LPIPS distance between Reference and GS-IR:', lpips_alex_score1_fourier_mean)\n",
    "print('LPIPS distance between Reference and TensoIR:', lpips_alex_score2_fourier_mean)\n",
    "print('LPIPS distance between Reference and GtV:', lpips_alex_score3_fourier_mean)\n",
    "print('LPIPS distance between Reference and Mine:', lpips_alex_score4_fourier_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fourier_score_vgg = []\n",
    "gsir_fourier_score_vgg = []\n",
    "tensoir_fourier_score_vgg = []\n",
    "gtv_fourier_score_vgg = []\n",
    "mine_fourier_score_vgg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images 0 to 10...\n",
      "Processing images 10 to 20...\n",
      "Processing images 20 to 30...\n",
      "Processing images 30 to 40...\n",
      "Processing images 40 to 50...\n",
      "Processing images 50 to 60...\n",
      "Processing images 60 to 70...\n",
      "Processing images 70 to 80...\n",
      "Processing images 80 to 90...\n",
      "Processing images 90 to 100...\n",
      "Processing images 100 to 110...\n",
      "Processing images 110 to 120...\n",
      "Processing images 120 to 130...\n",
      "Processing images 130 to 140...\n",
      "Processing images 140 to 150...\n",
      "Processing images 150 to 160...\n",
      "Processing images 160 to 170...\n",
      "Processing images 170 to 180...\n",
      "Processing images 180 to 190...\n",
      "Processing images 190 to 200...\n"
     ]
    }
   ],
   "source": [
    "interval = 10\n",
    "for i in range(0, number_of_imgs, interval):\n",
    "    print(f'Processing images {i} to {i+interval}...')\n",
    "    sub_batch_ref = ref_imgs_fourier[i:i+interval]\n",
    "    sub_batch_gsir = gsir_imgs_fourier[i:i+interval]\n",
    "    sub_batch_tensoir = tensoir_imgs_fourier[i:i+interval]\n",
    "    sub_batch_gtv = gtv_imgs_fourier[i:i+interval]\n",
    "    sub_batch_mine = mine_imgs_fourier[i:i+interval]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lpips_vgg_score0 = lpips_model_vgg(sub_batch_ref, sub_batch_ref)\n",
    "        lpips_vgg_score1 = lpips_model_vgg(sub_batch_ref, sub_batch_gsir)\n",
    "        lpips_vgg_score2 = lpips_model_vgg(sub_batch_ref, sub_batch_tensoir)\n",
    "        lpips_vgg_score3 = lpips_model_vgg(sub_batch_ref, sub_batch_gtv)\n",
    "        lpips_vgg_score4 = lpips_model_vgg(sub_batch_ref, sub_batch_mine)\n",
    "\n",
    "    ref_fourier_score_vgg.append(lpips_vgg_score0)\n",
    "    gsir_fourier_score_vgg.append(lpips_vgg_score1)\n",
    "    tensoir_fourier_score_vgg.append(lpips_vgg_score2)\n",
    "    gtv_fourier_score_vgg.append(lpips_vgg_score3)\n",
    "    mine_fourier_score_vgg.append(lpips_vgg_score4)\n",
    "\n",
    "ref_fourier_score_vgg = torch.cat(ref_fourier_score_vgg).squeeze()\n",
    "gsir_fourier_score_vgg = torch.cat(gsir_fourier_score_vgg).squeeze()\n",
    "tensoir_fourier_score_vgg = torch.cat(tensoir_fourier_score_vgg).squeeze()\n",
    "gtv_fourier_score_vgg = torch.cat(gtv_fourier_score_vgg).squeeze()\n",
    "mine_fourier_score_vgg = torch.cat(mine_fourier_score_vgg).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "LPIPS distance between Reference and GS-IR: tensor(0.0113)\n",
      "LPIPS distance between Reference and TensoIR: tensor(0.0109)\n",
      "LPIPS distance between Reference and GtV: tensor(0.0015)\n",
      "LPIPS distance between Reference and Mine: tensor(0.0090)\n"
     ]
    }
   ],
   "source": [
    "lpips_vgg_score0_fourier_mean = torch.mean(ref_fourier_score_vgg)\n",
    "lpips_vgg_score1_fourier_mean = torch.mean(gsir_fourier_score_vgg)\n",
    "lpips_vgg_score2_fourier_mean = torch.mean(tensoir_fourier_score_vgg)\n",
    "lpips_vgg_score3_fourier_mean = torch.mean(gtv_fourier_score_vgg)\n",
    "lpips_vgg_score4_fourier_mean = torch.mean(mine_fourier_score_vgg)\n",
    "\n",
    "print(f'Sanity Check: {lpips_vgg_score0_fourier_mean}')\n",
    "print('LPIPS distance between Reference and GS-IR:', lpips_vgg_score1_fourier_mean)\n",
    "print('LPIPS distance between Reference and TensoIR:', lpips_vgg_score2_fourier_mean)\n",
    "print('LPIPS distance between Reference and GtV:', lpips_vgg_score3_fourier_mean)\n",
    "print('LPIPS distance between Reference and Mine:', lpips_vgg_score4_fourier_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fourier_score_squeeze = []\n",
    "gsir_fourier_score_squeeze = []\n",
    "tensoir_fourier_score_squeeze = []\n",
    "gtv_fourier_score_squeeze = []\n",
    "mine_fourier_score_squeeze = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images 0 to 10...\n",
      "Processing images 10 to 20...\n",
      "Processing images 20 to 30...\n",
      "Processing images 30 to 40...\n",
      "Processing images 40 to 50...\n",
      "Processing images 50 to 60...\n",
      "Processing images 60 to 70...\n",
      "Processing images 70 to 80...\n",
      "Processing images 80 to 90...\n",
      "Processing images 90 to 100...\n",
      "Processing images 100 to 110...\n",
      "Processing images 110 to 120...\n",
      "Processing images 120 to 130...\n",
      "Processing images 130 to 140...\n",
      "Processing images 140 to 150...\n",
      "Processing images 150 to 160...\n",
      "Processing images 160 to 170...\n",
      "Processing images 170 to 180...\n",
      "Processing images 180 to 190...\n",
      "Processing images 190 to 200...\n"
     ]
    }
   ],
   "source": [
    "interval = 10\n",
    "for i in range(0, number_of_imgs, interval):\n",
    "    print(f'Processing images {i} to {i+interval}...')\n",
    "    sub_batch_ref = ref_imgs_fourier[i:i+interval]\n",
    "    sub_batch_gsir = gsir_imgs_fourier[i:i+interval]\n",
    "    sub_batch_tensoir = tensoir_imgs_fourier[i:i+interval]\n",
    "    sub_batch_gtv = gtv_imgs_fourier[i:i+interval]\n",
    "    sub_batch_mine = mine_imgs_fourier[i:i+interval]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lpips_squeeze_score0 = lpips_model_squeeze(sub_batch_ref, sub_batch_ref)\n",
    "        lpips_squeeze_score1 = lpips_model_squeeze(sub_batch_ref, sub_batch_gsir)\n",
    "        lpips_squeeze_score2 = lpips_model_squeeze(sub_batch_ref, sub_batch_tensoir)\n",
    "        lpips_squeeze_score3 = lpips_model_squeeze(sub_batch_ref, sub_batch_gtv)\n",
    "        lpips_squeeze_score4 = lpips_model_squeeze(sub_batch_ref, sub_batch_mine)\n",
    "\n",
    "    ref_fourier_score_squeeze.append(lpips_squeeze_score0)\n",
    "    gsir_fourier_score_squeeze.append(lpips_squeeze_score1)\n",
    "    tensoir_fourier_score_squeeze.append(lpips_squeeze_score2)\n",
    "    gtv_fourier_score_squeeze.append(lpips_squeeze_score3)\n",
    "    mine_fourier_score_squeeze.append(lpips_squeeze_score4)\n",
    "\n",
    "ref_fourier_score_squeeze = torch.cat(ref_fourier_score_squeeze).squeeze()\n",
    "gsir_fourier_score_squeeze = torch.cat(gsir_fourier_score_squeeze).squeeze()\n",
    "tensoir_fourier_score_squeeze = torch.cat(tensoir_fourier_score_squeeze).squeeze()\n",
    "gtv_fourier_score_squeeze = torch.cat(gtv_fourier_score_squeeze).squeeze()\n",
    "mine_fourier_score_squeeze = torch.cat(mine_fourier_score_squeeze).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check: 0.0\n",
      "LPIPS distance between Reference and GS-IR: tensor(0.0014)\n",
      "LPIPS distance between Reference and TensoIR: tensor(0.0013)\n",
      "LPIPS distance between Reference and GtV: tensor(0.0001)\n",
      "LPIPS distance between Reference and Mine: tensor(0.0008)\n"
     ]
    }
   ],
   "source": [
    "lpips_squeeze_score0_fourier_mean = torch.mean(ref_fourier_score_squeeze)\n",
    "lpips_squeeze_score1_fourier_mean = torch.mean(gsir_fourier_score_squeeze)\n",
    "lpips_squeeze_score2_fourier_mean = torch.mean(tensoir_fourier_score_squeeze)\n",
    "lpips_squeeze_score3_fourier_mean = torch.mean(gtv_fourier_score_squeeze)\n",
    "lpips_squeeze_score4_fourier_mean = torch.mean(mine_fourier_score_squeeze)\n",
    "\n",
    "print(f'Sanity Check: {lpips_squeeze_score0_fourier_mean}')\n",
    "print('LPIPS distance between Reference and GS-IR:', lpips_squeeze_score1_fourier_mean)\n",
    "print('LPIPS distance between Reference and TensoIR:', lpips_squeeze_score2_fourier_mean)\n",
    "print('LPIPS distance between Reference and GtV:', lpips_squeeze_score3_fourier_mean)\n",
    "print('LPIPS distance between Reference and Mine:', lpips_squeeze_score4_fourier_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the FLIP folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
