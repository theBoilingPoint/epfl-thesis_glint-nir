{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation\n",
    "\n",
    "This is the notebook for generating NeRF data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from IPython.display import clear_output\n",
    "from utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths\n",
    "\n",
    "First we need to specify the directories for the data generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"spot\"  # the name of the object/dataset you are gonna render. Name the folder and obj file exactly as this string.\n",
    "base_script = \"position\" if obj != \"sphere\" else \"test_glint_num\"\n",
    "nori_version = [\"nori\", \"nori_e10\", \"nori_e11\", \"nori_e12\", \"nori_e13\", \"nori_e14\"][0]\n",
    "result_dim = 800  # The dimension of the rendered image. Please match the dimension of the images in the dataset used by the pipeline.\n",
    "light_filename = \"./env_maps/clarens.exr\"\n",
    "\n",
    "\n",
    "#############################################\n",
    "#   Sample Generation Parameters\n",
    "#############################################\n",
    "sample_type = \"nerf\"\n",
    "nerf_dataset = \"chair\"  # feel free to use other nerf datasets' camera poses\n",
    "\n",
    "\n",
    "#############################################\n",
    "#   Rendering Parameters\n",
    "#############################################\n",
    "integrator_type = [\"mask\", \"image\"][0]  # the type of integrator defined in Nori.\n",
    "# This case you can just click \"run all\" without worrying about repetitive data genaration\n",
    "# If you want to fine tune the rendering parameters, please scroll down to the bottom of the notebook\n",
    "GENERATE_TRAINING_DATA = False\n",
    "GENERATE_TESTING_DATA = False\n",
    "\n",
    "\n",
    "#############################################\n",
    "#   Post Processing Parameters\n",
    "#   This part will only work if you have generated both images and masks\n",
    "#############################################\n",
    "img_format = \"png\"\n",
    "POST_PROCESSING_TRAIN = (\n",
    "    False  # if you want to apply post processing to the rendered images\n",
    ")\n",
    "POST_PROCESSING_TEST = False\n",
    "black_pixel_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = f\"{os.getcwd()}\"  # the absolute path to the current working directory\n",
    "\n",
    "scene_file = os.path.join(cwd, \"scripts\", \"render.xml\")\n",
    "\n",
    "# define these two if you want to use the preset camera positions in PhySG\n",
    "data_path = os.path.join(cwd, \"scripts\", \"camera_poses\")\n",
    "train_cam_file = os.path.join(data_path, f\"{nerf_dataset}_transforms_train.json\")\n",
    "test_cam_file = os.path.join(data_path, f\"{nerf_dataset}_transforms_test.json\")\n",
    "\n",
    "\n",
    "def get_out_path(category, data_type, data_format):\n",
    "    return os.path.join(\"out\", \"data\", obj, category, data_type, data_format)\n",
    "\n",
    "\n",
    "# training dataset\n",
    "train_img_png_dir = get_out_path(\"train\", \"image\", \"png\")\n",
    "train_img_exr_dir = get_out_path(\"train\", \"image\", \"exr\")\n",
    "train_mask_png_dir = get_out_path(\"train\", \"mask\", \"png\")\n",
    "train_mask_exr_dir = get_out_path(\"train\", \"mask\", \"exr\")\n",
    "\n",
    "# testing dataset\n",
    "test_img_png_dir = get_out_path(\"test\", \"image\", \"png\")\n",
    "test_img_exr_dir = get_out_path(\"test\", \"image\", \"exr\")\n",
    "test_mask_png_dir = get_out_path(\"test\", \"mask\", \"png\")\n",
    "test_mask_exr_dir = get_out_path(\"test\", \"mask\", \"exr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create those directories if they don't exist\n",
    "# train\n",
    "os.makedirs(train_img_png_dir, exist_ok=True)\n",
    "os.makedirs(train_img_exr_dir, exist_ok=True)\n",
    "os.makedirs(train_mask_png_dir, exist_ok=True)\n",
    "os.makedirs(train_mask_exr_dir, exist_ok=True)\n",
    "# test\n",
    "os.makedirs(test_img_png_dir, exist_ok=True)\n",
    "os.makedirs(test_img_exr_dir, exist_ok=True)\n",
    "os.makedirs(test_mask_png_dir, exist_ok=True)\n",
    "os.makedirs(test_mask_exr_dir, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get & Visualise Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training samples\n",
    "# data should already be sorted in the json file\n",
    "pos = get_points_from_nerf(train_cam_file)\n",
    "samples_train = np.array(pos)\n",
    "required_train_points = len(samples_train)\n",
    "\n",
    "visualise_points(samples_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting testing samples\n",
    "# data should already be sorted in the json file\n",
    "pos = get_points_from_nerf(test_cam_file)\n",
    "samples_test = np.array(pos)\n",
    "required_test_points = len(samples_test)\n",
    "\n",
    "visualise_points(samples_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render Required Images\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Basic Parameters for Rendering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for the .xml file\n",
    "sampleCount = \"32\"  # default val\n",
    "if integrator_type == \"mask\":\n",
    "    sampleCount = \"32\"\n",
    "elif integrator_type == \"image\":\n",
    "    sampleCount = \"1024\"  # default 1024\n",
    "\n",
    "fov = \"40\"  # PhySG default is 35, NeRF default is 40\n",
    "cam_pos = \"0.0, 0.0, 0.0\"  # a dummy value\n",
    "obj_filename = os.path.join(\"meshes\", sample_type, f\"{obj}.obj\")\n",
    "\n",
    "# fine-tuning rendering parameters\n",
    "glints_alpha = \"0.5\"  # the roughness of the material\n",
    "light_gamma = \"1.0\"\n",
    "light_toWorld = \"1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,-1.0,0.0,0.0,0.0,0.0,0.0,1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./scripts/{base_script}.xml\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "# create nori .xml script\n",
    "# the following params will not change for a batch of data\n",
    "bs_data = bs(data, \"xml\")\n",
    "bs_data.find(\"integrator\")[\"type\"] = integrator_type  # set the integrator type\n",
    "bs_data.find(\"sampler\").find(\"integer\")[\"value\"] = sampleCount  # set the sample count\n",
    "\n",
    "camera_param = bs_data.find(\"camera\")\n",
    "for child in camera_param.children:\n",
    "    if child.name == \"float\":\n",
    "        child[\"value\"] = fov\n",
    "    if child.name == \"integer\":\n",
    "        child[\"value\"] = result_dim\n",
    "\n",
    "if base_script == \"position\":\n",
    "    mesh_param = bs_data.find(\"mesh\")\n",
    "    for child in mesh_param:\n",
    "        if child.name == \"string\":\n",
    "            child[\"value\"] = obj_filename\n",
    "        if child.name == \"bsdf\":\n",
    "            child.find(\"float\")[\"value\"] = glints_alpha\n",
    "\n",
    "    emitter_param = bs_data.find(\"emitter\")\n",
    "    for child in emitter_param:\n",
    "        if child.name == \"string\":\n",
    "            child[\"value\"] = light_filename\n",
    "        if child.name == \"float\":\n",
    "            child[\"value\"] = light_gamma\n",
    "        if child.name == \"transform\":\n",
    "            child.find(\"matrix\")[\"value\"] = light_toWorld\n",
    "else:\n",
    "    meshes = bs_data.find_all(\"mesh\")\n",
    "    for mesh in meshes:\n",
    "        for child in mesh:\n",
    "            if child.name == \"string\":\n",
    "                cur_obj = child[\"value\"].split(\"/\")[-1]\n",
    "                child[\"value\"] = os.path.join(\"meshes\", \"test_glint_num\", cur_obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Rendering Main Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_img_path(is_train, img_name):\n",
    "    if is_train:\n",
    "        png_path = os.path.join(cwd, train_img_png_dir, f\"{img_name}.png\")\n",
    "        exr_path = os.path.join(cwd, train_img_exr_dir, f\"{img_name}.exr\")\n",
    "        mask_png_path = os.path.join(cwd, train_mask_png_dir, f\"{img_name}.png\")\n",
    "        mask_exr_path = os.path.join(cwd, train_mask_exr_dir, f\"{img_name}.exr\")\n",
    "    else:\n",
    "        png_path = os.path.join(cwd, test_img_png_dir, f\"{img_name}.png\")\n",
    "        exr_path = os.path.join(cwd, test_img_exr_dir, f\"{img_name}.exr\")\n",
    "        mask_png_path = os.path.join(cwd, test_mask_png_dir, f\"{img_name}.png\")\n",
    "        mask_exr_path = os.path.join(cwd, test_mask_exr_dir, f\"{img_name}.exr\")\n",
    "\n",
    "    return png_path, exr_path, mask_png_path, mask_exr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_output_imgs(png_path, exr_path, mask_png_path, mask_exr_path):\n",
    "    if bs_data.find(\"integrator\")[\"type\"] == \"image\":\n",
    "        subprocess.Popen([\"mv\", \"render.png\", png_path], cwd=f\"{cwd}/scripts\").wait()\n",
    "        subprocess.Popen([\"mv\", \"render.exr\", exr_path], cwd=f\"{cwd}/scripts\").wait()\n",
    "    else:\n",
    "        subprocess.Popen(\n",
    "            [\"mv\", \"render.png\", mask_png_path], cwd=f\"{cwd}/scripts\"\n",
    "        ).wait()\n",
    "        subprocess.Popen(\n",
    "            [\"mv\", \"render.exr\", mask_exr_path], cwd=f\"{cwd}/scripts\"\n",
    "        ).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_imgs(required_points, samples_lst, is_train):\n",
    "    for i in range(required_points):\n",
    "        cur_sample = samples_lst[i]\n",
    "        if is_train:\n",
    "            print(\n",
    "                f\"Rendering training {integrator_type} image {i} at camera position: {cur_sample}...\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"Rendering test {integrator_type} image {i} at camera position: {cur_sample}...\"\n",
    "            )\n",
    "\n",
    "        cur_sample = rotate_around_x(cur_sample, 90)\n",
    "        cur_sample = rotate_around_z(cur_sample, -180)\n",
    "\n",
    "        cam_pos = str(cur_sample.tolist()).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "\n",
    "        camera_param = bs_data.find(\"camera\")\n",
    "        for child in camera_param.children:\n",
    "            if child.name == \"transform\":\n",
    "                child.find(\"lookat\")[\"origin\"] = cam_pos\n",
    "\n",
    "        with open(scene_file, \"wb\") as f:\n",
    "            f.write(str(bs_data.prettify()).encode())\n",
    "\n",
    "        # stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT hides the console output\n",
    "        subprocess.Popen(\n",
    "            [f\"./{nori_version}\", scene_file, \"--no-gui\"],\n",
    "            cwd=\"./\",\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.STDOUT,\n",
    "        ).wait()\n",
    "\n",
    "        picture_name = f\"r_{i}\"\n",
    "\n",
    "        png_path, exr_path, mask_png_path, mask_exr_path = get_out_img_path(\n",
    "            is_train, picture_name\n",
    "        )\n",
    "\n",
    "        move_output_imgs(png_path, exr_path, mask_png_path, mask_exr_path)\n",
    "\n",
    "        # clear_output()\n",
    "\n",
    "    #  Apparently the rendered masks do not give (255,255,255) for the parts that are\n",
    "    #  supposed to be purely white. So we need to correct the pixel colour\n",
    "    if bs_data.find(\"integrator\")[\"type\"] == \"mask\":\n",
    "        if is_train:\n",
    "            replace_masks(train_mask_png_dir)\n",
    "        else:\n",
    "            replace_masks(test_mask_png_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_TRAINING_DATA:\n",
    "    render_imgs(required_train_points, samples_train, True)\n",
    "if GENERATE_TESTING_DATA:\n",
    "    render_imgs(required_test_points, samples_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "\n",
    "This step combines the images and masks by removing the background of the images where the corresponding mask pixels are close to black.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post processing results directory\n",
    "post_input_dir = os.path.join(\"out\", \"data\", obj)\n",
    "post_output_dir = os.path.join(\"out\", \"post_res\", sample_type, obj)\n",
    "\n",
    "os.makedirs(post_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if POST_PROCESSING_TRAIN:\n",
    "    process_rendered_results(\n",
    "        post_input_dir,\n",
    "        post_output_dir,\n",
    "        \"train\",\n",
    "        img_format,\n",
    "        black_pixel_threshold,\n",
    "    )\n",
    "if POST_PROCESSING_TEST:\n",
    "    process_rendered_results(\n",
    "        post_input_dir,\n",
    "        post_output_dir,\n",
    "        \"test\",\n",
    "        img_format,\n",
    "        black_pixel_threshold,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
