{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Forward Rendering Pipeline\n",
    "\n",
    "The forward rendering pipeline should be combined with that of PhySG rather than directly employing Unity's URP/HDRP. The only part that should be extracted from Unity's pipeline is the specular colour rendering in `GlintForwardLitPass`, as geometry and albedo are nicely handled by PhySG.\n",
    "\n",
    "Nevertheless, details of PhySG's pipeline can be found [here](https://kai-46.github.io/PhySG-website/) the details of Unity's URP can be found [here](https://nedmakesgames.medium.com/writing-unity-urp-shaders-with-code-part-1-the-graphics-pipeline-and-you-798cbc941cea).\n",
    "\n",
    "> **Watch Out!!!**\n",
    ">\n",
    "> - HLSL uses column major. When detailing with matrices that have more than 1 dimension, remember to check that the calculations are correct. Potentially problematic functions include:\n",
    ">   - `GetGradientEllipse(duvdx, duvdy)`\n",
    ">   - `SampleGlintGridSimplex(uv, gridSeed, slope, footprintArea, targetNDF, gridWeight)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.224681300Z",
     "start_time": "2023-10-20T10:52:55.928283200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import struct\n",
    "import array\n",
    "import imageio\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.238292100Z",
     "start_time": "2023-10-20T10:52:58.230229100Z"
    }
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "EPSILON = 1e-6\n",
    "DEG2RAD = 0.01745329251\n",
    "RAD2DEG = 57.2957795131\n",
    "ZERO = torch.tensor(0.0, requires_grad=True)\n",
    "ONE = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.283791Z",
     "start_time": "2023-10-20T10:52:58.239292Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_valid(tensor):\n",
    "    valid = True\n",
    "    if torch.any(torch.isnan(tensor)):\n",
    "        print(f\"The input tensor has NaN values.\")\n",
    "        valid = False\n",
    "    if torch.any(torch.isinf(tensor)):\n",
    "        print(f\"The input tensor has Inf values.\")\n",
    "        valid = False\n",
    "\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.285793200Z",
     "start_time": "2023-10-20T10:52:58.255793600Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_zeros(tensor):\n",
    "    res = torch.where(tensor == 0.0, tensor.mean(), tensor)\n",
    "    assert torch.all(res != 0.0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.285793200Z",
     "start_time": "2023-10-20T10:52:58.271793300Z"
    }
   },
   "outputs": [],
   "source": [
    "def toIntApprox(tensor):\n",
    "    return torch.where(tensor >= 0.0, torch.floor(tensor), torch.ceil(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def normalise(tensor):\n",
    "    return (tensor - tensor.min()) / torch.clamp(tensor.max() - tensor.min(), EPSILON)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.307414700Z",
     "start_time": "2023-10-20T10:52:58.286875Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.367072500Z",
     "start_time": "2023-10-20T10:52:58.302918500Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param u: float3/4\n",
    "# @param mu: float\n",
    "# @param sigma: float\n",
    "#\n",
    "# @return float3\n",
    "def sampleNormalDistribution(u, mu, sigma):\n",
    "    # 2.0 * u - 1.0 must be within (-1.0, 1.0)\n",
    "    return (sigma * 1.414213).unsqueeze(-1) * torch.erfinv(\n",
    "        2.0 * u - 1.0\n",
    "    ) + mu.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.369071800Z",
     "start_time": "2023-10-20T10:52:58.316413400Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param v: uint3\n",
    "#\n",
    "# @return float3\n",
    "def pcg3dFloat(v):\n",
    "    v = v * np.uint32(1664525) + np.uint32(1013904223)\n",
    "\n",
    "    v[..., 0] += v[..., 1] * v[..., 2]\n",
    "    v[..., 1] += v[..., 2] * v[..., 0]\n",
    "    v[..., 2] += v[..., 0] * v[..., 1]\n",
    "\n",
    "    v ^= v >> np.uint32(16)\n",
    "\n",
    "    v[..., 0] += v[..., 1] * v[..., 2]\n",
    "    v[..., 1] += v[..., 2] * v[..., 0]\n",
    "    v[..., 2] += v[..., 0] * v[..., 1]\n",
    "\n",
    "    return torch.tensor(v * (1.0 / 4294967296.0))\n",
    "\n",
    "\n",
    "def mt19937_3dFloat(dim, seed):\n",
    "    g = torch.Generator()  # TODO: remember to add device='cuda' if using GPU\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    return torch.clamp(torch.rand(dim, generator=g, requires_grad=True), EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.369573100Z",
     "start_time": "2023-10-20T10:52:58.333915700Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param p3: float3\n",
    "#\n",
    "# @return float\n",
    "def HashWithoutSine13(p3):\n",
    "    p3 = torch.frac(p3 * 0.1031)\n",
    "    p3 += torch.sum(p3 * (p3[:, [1, 2, 0]] + 33.33), dim=1).unsqueeze(-1)\n",
    "\n",
    "    return torch.frac((p3[..., 0] + p3[..., 1]) * p3[..., 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.370069900Z",
     "start_time": "2023-10-20T10:52:58.352028500Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param duvdx: float2\n",
    "# @param duvdy: float2\n",
    "# @param ellipseMajor: float2\n",
    "# @param ellipseMinor: float2\n",
    "def GetGradientEllipse(duvdx, duvdy):\n",
    "    # Construct Jacobian matrix\n",
    "    # Note that HLSL is column major: https://stackoverflow.com/questions/22756121/confuse-with-row-major-and-column-major-matrix-multiplication-in-hlsl#:~:text=HLSL%20uses%20Column%2DMajor%20and%20XNAMath%20uses%20ROW%2DMajor.\n",
    "    J = torch.transpose(torch.stack([duvdx, duvdy], dim=2), 1, 2)\n",
    "    # Check if determinant is zero and replace the matrices\n",
    "    J = torch.where(\n",
    "        torch.det(J).unsqueeze(1).unsqueeze(2) == 0,\n",
    "        torch.randn((2, 2), requires_grad=True),\n",
    "        J,\n",
    "    )\n",
    "    J = torch.linalg.inv(J)\n",
    "    J = torch.matmul(J, torch.transpose(J, 1, 2))\n",
    "\n",
    "    a = J[..., 0, 0]\n",
    "    c = J[..., 1, 0]\n",
    "    d = J[..., 1, 1]\n",
    "\n",
    "    T = a + d\n",
    "    D = torch.linalg.det(J)\n",
    "    # They are meant to be > 0.0\n",
    "    L1 = remove_zeros(torch.abs(T / 2.0 - torch.pow(T * T / 3.99999 - D, 0.5)))\n",
    "    L2 = remove_zeros(torch.abs(T / 2.0 + torch.pow(T * T / 3.99999 - D, 0.5)))\n",
    "\n",
    "    A0 = torch.stack((L1 - d, c), dim=-1)\n",
    "    A1 = torch.stack((L2 - d, c), dim=-1)\n",
    "    r0 = 1.0 / torch.sqrt(L1)\n",
    "    r1 = 1.0 / torch.sqrt(L2)\n",
    "\n",
    "    ellipseMajor = torch.nn.functional.normalize(A0, dim=-1) * r0.unsqueeze(-1)\n",
    "    ellipseMinor = torch.nn.functional.normalize(A1, dim=-1) * r1.unsqueeze(-1)\n",
    "\n",
    "    return ellipseMajor, ellipseMinor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.405876400Z",
     "start_time": "2023-10-20T10:52:58.365067600Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param v: float3\n",
    "#\n",
    "# @return float2\n",
    "def VectorToSlope(v):\n",
    "    return torch.tensor([-v[0] / v[2], -v[1] / v[2]])\n",
    "\n",
    "\n",
    "# @param s: float2\n",
    "#\n",
    "# @return float3\n",
    "def SlopeToVector(s):\n",
    "    z = 1 / torch.sqrt(s[0] * s[0] + s[1] * s[1] + 1)\n",
    "    x = s[0] * z\n",
    "    y = s[1] * z\n",
    "\n",
    "    return torch.tensor([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.463390200Z",
     "start_time": "2023-10-20T10:52:58.380071400Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param uv: float2\n",
    "# @param rotation: float\n",
    "# @param mid: float2\n",
    "#\n",
    "# @return float2\n",
    "def RotateUV(uv, rotation, mid):\n",
    "    return torch.stack(\n",
    "        (\n",
    "            torch.cos(rotation) * (uv[..., 0] - mid[0])\n",
    "            + torch.sin(rotation) * (uv[..., 1] - mid[1])\n",
    "            + mid[0],\n",
    "            torch.cos(rotation) * (uv[..., 1] - mid[1])\n",
    "            - torch.sin(rotation) * (uv[..., 0] - mid[0])\n",
    "            + mid[1],\n",
    "        ),\n",
    "        dim=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.464889200Z",
     "start_time": "2023-10-20T10:52:58.395337400Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param values: float4\n",
    "# @param valuesLerp: float2\n",
    "#\n",
    "# @return float\n",
    "def BilinearLerp(values, valuesLerp):\n",
    "    resultX = torch.lerp(values[..., 0], values[..., 2], valuesLerp[..., 0])\n",
    "    resultY = torch.lerp(values[..., 1], values[..., 3], valuesLerp[..., 0])\n",
    "\n",
    "    return torch.lerp(resultX, resultY, valuesLerp[..., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.466892100Z",
     "start_time": "2023-10-20T10:52:58.413888600Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param s: float\n",
    "# @param a1: float\n",
    "# @param a2: float\n",
    "# @param b1: float\n",
    "# @param b2: float\n",
    "#\n",
    "# @return float\n",
    "def Remap(s, a1, a2, b1, b2):\n",
    "    return b1 + (s - a1) * (b2 - b1) / (a2 - a1)\n",
    "\n",
    "\n",
    "# @param s: float\n",
    "# @param b1: float\n",
    "# @param b2: float\n",
    "#\n",
    "# @return float\n",
    "def Remap01To(s, b1, b2):\n",
    "    return b1 + s * (b2 - b1)\n",
    "\n",
    "\n",
    "# @param s: float or float4\n",
    "# @param a1: float or float4\n",
    "# @param a2: float or float4\n",
    "#\n",
    "# @return float or float4\n",
    "def RemapTo01(s, a1, a2):\n",
    "    return (s - a1) / (a2 - a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.466892100Z",
     "start_time": "2023-10-20T10:52:58.424385800Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param p: float3\n",
    "# @param v1: float3\n",
    "# @param v2: float3\n",
    "# @param v3: float3\n",
    "# @param v4: float3\n",
    "#\n",
    "# @return float4\n",
    "def GetBarycentricWeightsTetrahedron(p, v1, v2, v3, v4):\n",
    "    c11, c21, c31, c41 = v1 - v4, v2 - v4, v3 - v4, v4 - p\n",
    "\n",
    "    m1 = c31[..., 1:] / remove_zeros(c31[..., 0]).unsqueeze(-1)\n",
    "    c12 = c11[..., 1:] - c11[..., 0].unsqueeze(-1) * m1\n",
    "    c22 = c21[..., 1:] - c21[..., 0].unsqueeze(-1) * m1\n",
    "    c32 = c41[..., 1:] - c41[..., 0].unsqueeze(-1) * m1\n",
    "\n",
    "    m2 = c22[..., 1] / remove_zeros(c22[..., 0])\n",
    "    uvwk_0 = (c32[..., 0] * m2 - c32[..., 1]) / remove_zeros(\n",
    "        c12[..., 1] - c12[..., 0] * m2\n",
    "    )\n",
    "    uvwk_1 = -(c32[..., 0] + c12[..., 0] * uvwk_0) / remove_zeros(c22[..., 0])\n",
    "    uvwk_2 = -(\n",
    "        c41[..., 0] + c21[..., 0] * uvwk_1 + c11[..., 0] * uvwk_0\n",
    "    ) / remove_zeros(c31[..., 0])\n",
    "    uvwk_3 = 1.0 - uvwk_2 - uvwk_1 - uvwk_0\n",
    "\n",
    "    # The range of the return values depends on the input vertices and the position of the point p relative to the\n",
    "    # tetrahedron. In general, the barycentric coordinates should satisfy the condition 0 <= uvwk.x, uvwk.y, uvwk.z, uvwk.w <= 1\n",
    "    # and uvwk.x + uvwk.y + uvwk.z + uvwk.w = 1. These conditions ensure that the point p lies within the tetrahedron.\n",
    "    return torch.nn.functional.softmax(\n",
    "        torch.stack((uvwk_0, uvwk_1, uvwk_2, uvwk_3), dim=-1), dim=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the [HLSL documentation](https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-scalar) for the number of bits of each data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.467391500Z",
     "start_time": "2023-10-20T10:52:58.442385200Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param input: uint32\n",
    "#\n",
    "# @return float32\n",
    "def f16tof32(input):\n",
    "    packed_input = [struct.pack(\"IIII\", x[0], x[1], x[2], x[3]) for x in input]\n",
    "    return np.float32([struct.unpack(\"ffff\", y) for y in packed_input])\n",
    "\n",
    "\n",
    "# @param input: float32\n",
    "#\n",
    "# return uint32 (stored in the low-half of the uint.)\n",
    "def f32tof16(input):\n",
    "    return np.uint32(\n",
    "        struct.unpack(\"I\", struct.pack(\"f\", input))[0]\n",
    "    )  # make it explicit as a uint32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.488888500Z",
     "start_time": "2023-10-20T10:52:58.457888200Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param input: float4 (here we have tensors)\n",
    "# @param a: float4\n",
    "# @param b: float4\n",
    "def UnpackFloatParallel4(input):\n",
    "    input_in_bytes = [\n",
    "        struct.pack(\"ffff\", x[0], x[1], x[2], x[3]) for x in input.tolist()\n",
    "    ]\n",
    "    uintInput = np.uint32([array.array(\"I\", x) for x in input_in_bytes])\n",
    "    a = torch.tensor(f16tof32(uintInput >> 16))\n",
    "    b = torch.tensor(f16tof32(uintInput))\n",
    "\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Map Initialisation\n",
    "\n",
    "The noise map is generated from Unity. Since the noise map has randomness involved and stays constant during rendering, it is unnecessary to reimplement this part in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.577329600Z",
     "start_time": "2023-10-20T10:52:58.471887600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[6.9222e-05, 1.7004e-09, 3.1239e-07, 8.9268e-19],\n         [3.1239e-07, 8.9268e-19, 6.7638e-08, 1.3198e-11],\n         [6.7638e-08, 1.3198e-11, 9.3990e-06, 4.0279e-07],\n         ...,\n         [7.7720e-04, 9.0422e-07, 2.1206e-07, 5.1943e-03],\n         [2.1206e-07, 5.1943e-03, 1.8476e-04, 1.9808e-07],\n         [1.8476e-04, 1.9808e-07, 6.9222e-05, 1.7004e-09]],\n\n        [[4.0038e-03, 6.9222e-05, 3.0856e-03, 3.1239e-07],\n         [3.0856e-03, 3.1239e-07, 5.7582e-06, 6.7638e-08],\n         [5.7582e-06, 6.7638e-08, 2.8748e-04, 9.3990e-06],\n         ...,\n         [2.9713e-03, 7.7720e-04, 1.3319e-04, 2.1206e-07],\n         [1.3319e-04, 2.1206e-07, 3.0629e-03, 1.8476e-04],\n         [3.0629e-03, 1.8476e-04, 4.0038e-03, 6.9222e-05]],\n\n        [[1.2987e-18, 4.0038e-03, 3.0278e-06, 3.0856e-03],\n         [3.0278e-06, 3.0856e-03, 5.1768e-17, 5.7582e-06],\n         [5.1768e-17, 5.7582e-06, 6.1151e-05, 2.8748e-04],\n         ...,\n         [4.8815e-05, 2.9713e-03, 3.4283e-04, 1.3319e-04],\n         [3.4283e-04, 1.3319e-04, 2.1472e-03, 3.0629e-03],\n         [2.1472e-03, 3.0629e-03, 1.2987e-18, 4.0038e-03]],\n\n        ...,\n\n        [[2.3578e-04, 3.9633e-05, 8.2880e-11, 5.7602e-03],\n         [8.2880e-11, 5.7602e-03, 1.0544e-08, 3.8591e-08],\n         [1.0544e-08, 3.8591e-08, 1.8427e-04, 5.1014e-04],\n         ...,\n         [7.8096e-04, 5.1080e-05, 2.4995e-06, 4.8813e-05],\n         [2.4995e-06, 4.8813e-05, 6.9515e-04, 5.8781e-06],\n         [6.9515e-04, 5.8781e-06, 2.3578e-04, 3.9633e-05]],\n\n        [[4.1984e-04, 2.3578e-04, 7.5246e-04, 8.2880e-11],\n         [7.5246e-04, 8.2880e-11, 4.9165e-05, 1.0544e-08],\n         [4.9165e-05, 1.0544e-08, 2.7049e-07, 1.8427e-04],\n         ...,\n         [3.3071e-05, 7.8096e-04, 1.6829e-07, 2.4995e-06],\n         [1.6829e-07, 2.4995e-06, 6.0494e-05, 6.9515e-04],\n         [6.0494e-05, 6.9515e-04, 4.1984e-04, 2.3578e-04]],\n\n        [[1.7004e-09, 4.1984e-04, 8.9268e-19, 7.5246e-04],\n         [8.9268e-19, 7.5246e-04, 1.3198e-11, 4.9165e-05],\n         [1.3198e-11, 4.9165e-05, 4.0279e-07, 2.7049e-07],\n         ...,\n         [9.0422e-07, 3.3071e-05, 5.1943e-03, 1.6829e-07],\n         [5.1943e-03, 1.6829e-07, 1.9808e-07, 6.0494e-05],\n         [1.9808e-07, 6.0494e-05, 1.7004e-09, 4.1984e-04]]],\n       requires_grad=True)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noiseMapExr = imageio.v3.imread(\"./noise_maps/noise_map_256.exr\")\n",
    "_Glint2023NoiseMap = torch.from_numpy(noiseMapExr).requires_grad_()  # Texture2D<float4>\n",
    "_Glint2023NoiseMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.579328300Z",
     "start_time": "2023-10-20T10:52:58.564664800Z"
    }
   },
   "outputs": [],
   "source": [
    "_Glint2023NoiseMapSize = _Glint2023NoiseMap.shape[0]\n",
    "target_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.683765100Z",
     "start_time": "2023-10-20T10:52:58.581828400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate random indices\n",
    "random_indices = torch.randint(0, _Glint2023NoiseMapSize, (target_dim, target_dim))\n",
    "# Use the random indices to select elements from the tensor\n",
    "selected_values = _Glint2023NoiseMap[random_indices, random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.693301700Z",
     "start_time": "2023-10-20T10:52:58.612331500Z"
    }
   },
   "outputs": [],
   "source": [
    "# update values\n",
    "_Glint2023NoiseMap = selected_values\n",
    "_Glint2023NoiseMapSize = _Glint2023NoiseMap.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glint BRDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.695816700Z",
     "start_time": "2023-10-20T10:52:58.627706500Z"
    }
   },
   "outputs": [],
   "source": [
    "# vars\n",
    "_ScreenSpaceScale = 1.5  # float\n",
    "_LogMicrofacetDensity = 20.0  # float\n",
    "_MicrofacetRoughness = 0.025  # float\n",
    "_DensityRandomization = 1.5  # float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.696315200Z",
     "start_time": "2023-10-20T10:52:58.641263400Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_vals = batch_size * _Glint2023NoiseMapSize * _Glint2023NoiseMapSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.712817Z",
     "start_time": "2023-10-20T10:52:58.672264300Z"
    }
   },
   "outputs": [],
   "source": [
    "_ScreenSpaceScale = torch.rand((num_vals,), requires_grad=True)\n",
    "_LogMicrofacetDensity = torch.rand((num_vals,), requires_grad=True)\n",
    "_MicrofacetRoughness = torch.rand((num_vals,), requires_grad=True)\n",
    "_DensityRandomization = torch.rand((num_vals,), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.745820400Z",
     "start_time": "2023-10-20T10:52:58.691792Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param slope: float2\n",
    "# @param slopeRandOffset: float2\n",
    "# @param out outUniform: float4\n",
    "# @param out outGaussian: float4\n",
    "# @param out slopeLerp: float2\n",
    "def CustomRand4Texture(slope, slopeRandOffset):\n",
    "    slope2 = torch.abs(slope) / _MicrofacetRoughness.unsqueeze(-1)\n",
    "    slope2 = slope2 + (slopeRandOffset * _Glint2023NoiseMapSize)\n",
    "    slopeLerp = torch.frac(slope2)\n",
    "    # slopeCoord = (toIntApprox(torch.floor(slope2)) % _Glint2023NoiseMapSize)\n",
    "    #\n",
    "    # packedRead = _Glint2023NoiseMap[slopeCoord[...,0].long(), slopeCoord[...,1].long()]\n",
    "    # outUniform, outGaussian = UnpackFloatParallel4(packedRead)\n",
    "    # TODO: Uniform random numbers generated within the range of what would've been generated by UnpackFloatParallel4()\n",
    "    outUniform = (\n",
    "        torch.rand((slope.shape[0], 4), requires_grad=True) * (2**31 - 1) - 2**31\n",
    "    )\n",
    "    outGaussian = (\n",
    "        torch.rand((slope.shape[0], 4), requires_grad=True) * (2**31 - 1) - 2**31\n",
    "    )\n",
    "\n",
    "    return outUniform, outGaussian, slopeLerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.809747100Z",
     "start_time": "2023-10-20T10:52:58.710317900Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param randB: float4\n",
    "# @param randG: float4\n",
    "# @param slopeLerp: float2\n",
    "# @param footprintOneHitProba: float\n",
    "# @param binomialSmoothWidth: float\n",
    "# @param footprintMean: float\n",
    "# @param footprintSTD: float\n",
    "# @param microfacetCount: float\n",
    "#\n",
    "# @return float\n",
    "def GenerateAngularBinomialValueForSurfaceCell(\n",
    "    randB,\n",
    "    randG,\n",
    "    slopeLerp,\n",
    "    footprintOneHitProba,\n",
    "    binomialSmoothWidth,\n",
    "    footprintMean,\n",
    "    footprintSTD,\n",
    "    microfacetCount,\n",
    "):\n",
    "    gating = torch.ones((len(binomialSmoothWidth), 4), requires_grad=True)\n",
    "    gating = torch.where(\n",
    "        binomialSmoothWidth.unsqueeze(-1) * gating > EPSILON,\n",
    "        torch.clamp(\n",
    "            RemapTo01(\n",
    "                randB,\n",
    "                (footprintOneHitProba + binomialSmoothWidth).unsqueeze(-1),\n",
    "                (footprintOneHitProba - binomialSmoothWidth).unsqueeze(-1),\n",
    "            ),\n",
    "            0.0,\n",
    "            1.0,\n",
    "        ),\n",
    "        torch.where(randB < footprintOneHitProba.unsqueeze(-1), ONE, ZERO),\n",
    "    )\n",
    "\n",
    "    # Compute gauss\n",
    "    gauss = randG * footprintSTD.unsqueeze(-1) + footprintMean.unsqueeze(-1)\n",
    "    gauss = torch.clamp(torch.floor(gauss), ZERO, microfacetCount.unsqueeze(-1))\n",
    "\n",
    "    # Compute results\n",
    "    results = gating * (1.0 + gauss)\n",
    "\n",
    "    # Perform BilinearLerp\n",
    "    return BilinearLerp(results, slopeLerp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.812750500Z",
     "start_time": "2023-10-20T10:52:58.737322200Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param uv: float2\n",
    "# @param gridSeed: uint\n",
    "# @param slope: float2\n",
    "# @param footprintArea: float\n",
    "# @param targetNDF: float\n",
    "# @param gridWeight: float\n",
    "#\n",
    "# @return float\n",
    "def SampleGlintGridSimplex(uv, gridSeed, slope, footprintArea, targetNDF, gridWeight):\n",
    "    # Get surface space glint simplex grid cell\n",
    "    gridToSkewedGrid = torch.tensor(\n",
    "        [[1.0, -0.57735027], [0.0, 1.15470054]], requires_grad=True\n",
    "    )\n",
    "    skewedCoord = torch.matmul(gridToSkewedGrid, uv.t()).t()\n",
    "    # baseId = torch.floor(skewedCoord).to(torch.int)\n",
    "    baseId = toIntApprox(torch.floor(skewedCoord))\n",
    "    temp = torch.cat(\n",
    "        (\n",
    "            torch.frac(skewedCoord),\n",
    "            torch.zeros(len(skewedCoord), 1, requires_grad=True),\n",
    "        ),\n",
    "        dim=-1,\n",
    "    )\n",
    "    temp[..., 2] = 1.0 - temp[..., 0] - temp[..., 1]\n",
    "    s = torch.where(-temp[..., 2] >= 0.0, ONE, ZERO)\n",
    "    s2 = 2.0 * s - 1.0\n",
    "    # glint0 = baseId + torch.stack((s,s), dim=-1).to(torch.int)\n",
    "    # glint1 = baseId + torch.stack((s, 1.0 - s), dim=-1).to(torch.int)\n",
    "    # glint2 = baseId + torch.stack((1.0 - s, s), dim=-1).to(torch.int)\n",
    "    glint0 = baseId + toIntApprox(torch.stack((s, s), dim=-1))\n",
    "    glint1 = baseId + toIntApprox(torch.stack((s, 1.0 - s), dim=-1))\n",
    "    glint2 = baseId + toIntApprox(torch.stack((1.0 - s, s), dim=-1))\n",
    "    barycentrics = torch.stack(\n",
    "        (-temp[..., 2] * s2, s - temp[..., 1] * s2, s - temp[..., 0] * s2), dim=-1\n",
    "    )\n",
    "\n",
    "    # Generate per surface cell random numbers\n",
    "    # It's produce overflow runtime warning but uint is indeed 32 bits in HLSL and the code is basically copied pasted\n",
    "    # So I don't think I could do much about it\n",
    "    # pcg3dFloat already ensured that the param will be converted to np.uint32\n",
    "    # rand0 = pcg3dFloat(np.hstack((np.uint32(glint0.detach().numpy() + 2147483648), gridSeed.reshape(-1, 1))))\n",
    "    # rand1 = pcg3dFloat(np.hstack((np.uint32(glint1.detach().numpy() + 2147483648), gridSeed.reshape(-1, 1))))\n",
    "    # rand2 = pcg3dFloat(np.hstack((np.uint32(glint2.detach().numpy() + 2147483648), gridSeed.reshape(-1, 1))))\n",
    "    rand0 = mt19937_3dFloat(\n",
    "        (glint0.shape[0], 3), int((torch.sum(glint0) + gridSeed.mean()).item())\n",
    "    )\n",
    "    rand1 = mt19937_3dFloat(\n",
    "        (glint1.shape[0], 3), int((torch.sum(glint1) + gridSeed.mean()).item())\n",
    "    )\n",
    "    rand2 = mt19937_3dFloat(\n",
    "        (glint2.shape[0], 3), int((torch.sum(glint2) + gridSeed.mean()).item())\n",
    "    )\n",
    "\n",
    "    # Get per surface cell per slope cell random numbers\n",
    "    rand0SlopesB, rand0SlopesG, slopeLerp0 = CustomRand4Texture(slope, rand0[..., 1:])\n",
    "    rand1SlopesB, rand1SlopesG, slopeLerp1 = CustomRand4Texture(slope, rand1[..., 1:])\n",
    "    rand2SlopesB, rand2SlopesG, slopeLerp2 = CustomRand4Texture(slope, rand2[..., 1:])\n",
    "\n",
    "    # Compute microfacet count with randomization\n",
    "    logDensityRand = torch.clamp(\n",
    "        sampleNormalDistribution(\n",
    "            torch.stack((rand0[..., 0], rand1[..., 0], rand2[..., 0]), dim=-1),\n",
    "            _LogMicrofacetDensity,\n",
    "            _DensityRandomization,\n",
    "        ),\n",
    "        0.0,\n",
    "        50.0,\n",
    "    )\n",
    "\n",
    "    microfacetCount = torch.clamp(\n",
    "        footprintArea.unsqueeze(-1) * torch.exp(logDensityRand), min=EPSILON\n",
    "    )\n",
    "\n",
    "    # Compute binomial properties\n",
    "    hitProba = torch.clamp(\n",
    "        _MicrofacetRoughness * targetNDF, 0.0, 1.0\n",
    "    )  # probability of hitting desired half vector in NDF distribution\n",
    "    microfacetCountBlended = microfacetCount * gridWeight.unsqueeze(-1)\n",
    "    microfacetCountBlended = torch.clamp(microfacetCountBlended, min=1.0)\n",
    "\n",
    "    footprintOneHitProba = 1.0 - torch.pow(\n",
    "        (1.0 - hitProba).unsqueeze(-1), microfacetCountBlended\n",
    "    )  # probability of hitting at least one microfacet in footprint\n",
    "    footprintMean = (microfacetCountBlended - 1.0) * hitProba.unsqueeze(\n",
    "        -1\n",
    "    )  # Expected value of number of hits in the footprint given already one hit\n",
    "    footprintSTD = torch.sqrt(\n",
    "        torch.clamp(\n",
    "            (microfacetCountBlended - 1.0)\n",
    "            * hitProba.unsqueeze(-1)\n",
    "            * (1.0 - hitProba.unsqueeze(-1)),\n",
    "            EPSILON,\n",
    "        )\n",
    "    )  # Standard deviation of number of hits in the footprint given already one hit, clampped for numerical stability\n",
    "\n",
    "    binomialSmoothWidth = (\n",
    "        0.1\n",
    "        * torch.clamp(footprintOneHitProba * 10, 0.0, 1.0)\n",
    "        * torch.clamp((1.0 - footprintOneHitProba) * 10, 0.0, 1.0)\n",
    "    )\n",
    "\n",
    "    # Generate numbers of reflecting microfacets\n",
    "    result0 = GenerateAngularBinomialValueForSurfaceCell(\n",
    "        rand0SlopesB,\n",
    "        rand0SlopesG,\n",
    "        slopeLerp0,\n",
    "        footprintOneHitProba[..., 0],\n",
    "        binomialSmoothWidth[..., 0],\n",
    "        footprintMean[..., 0],\n",
    "        footprintSTD[..., 0],\n",
    "        microfacetCountBlended[..., 0],\n",
    "    )\n",
    "    result1 = GenerateAngularBinomialValueForSurfaceCell(\n",
    "        rand1SlopesB,\n",
    "        rand1SlopesG,\n",
    "        slopeLerp1,\n",
    "        footprintOneHitProba[..., 1],\n",
    "        binomialSmoothWidth[..., 1],\n",
    "        footprintMean[..., 1],\n",
    "        footprintSTD[..., 1],\n",
    "        microfacetCountBlended[..., 1],\n",
    "    )\n",
    "    result2 = GenerateAngularBinomialValueForSurfaceCell(\n",
    "        rand2SlopesB,\n",
    "        rand2SlopesG,\n",
    "        slopeLerp2,\n",
    "        footprintOneHitProba[..., 2],\n",
    "        binomialSmoothWidth[..., 2],\n",
    "        footprintMean[..., 2],\n",
    "        footprintSTD[..., 2],\n",
    "        microfacetCountBlended[..., 2],\n",
    "    )\n",
    "\n",
    "    # Interpolate result for glint grid cell\n",
    "    results = torch.stack((result0, result1, result2), dim=-1) / microfacetCount\n",
    "\n",
    "    return torch.sum(results * barycentrics, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.813250600Z",
     "start_time": "2023-10-20T10:52:58.780997900Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param centerSpecialCase: bool\n",
    "# @param thetaBinLerp: inout float\n",
    "# @param ratioLerp: float\n",
    "# @param lodLerp: float\n",
    "# @param out p0: out float3\n",
    "# @param out p1: out float3\n",
    "# @param out p2: out float3\n",
    "# @param out p3: out float3\n",
    "def GetAnisoCorrectingGridTetrahedron(\n",
    "    centerSpecialCase, thetaBinLerp, ratioLerp, lodLerp\n",
    "):\n",
    "    p0 = torch.ones((len(centerSpecialCase), 3), requires_grad=True)\n",
    "    p1 = torch.ones((len(centerSpecialCase), 3), requires_grad=True)\n",
    "    p2 = torch.ones((len(centerSpecialCase), 3), requires_grad=True)\n",
    "    p3 = torch.ones((len(centerSpecialCase), 3), requires_grad=True)\n",
    "\n",
    "    # vars for centerSpecialCase\n",
    "    upper_pyramid_mask = torch.where(lodLerp > 1.0 - ratioLerp, ONE, ZERO)\n",
    "    lower_pyramid_mask = torch.where(lodLerp < 1.0 - ratioLerp, ONE, ZERO)\n",
    "    left_up_tetrahedron_mask = torch.where(\n",
    "        RemapTo01(lodLerp, 1.0 - ratioLerp, 1.0) > thetaBinLerp, ONE, ZERO\n",
    "    )\n",
    "\n",
    "    # vars for normal case\n",
    "    normal_case_mask = 1.0 - centerSpecialCase  # flipping the bits using 1.0 - bit\n",
    "    prismA_mask = torch.where(\n",
    "        (thetaBinLerp < 0.5) & (thetaBinLerp * 2.0 < ratioLerp), ONE, ZERO\n",
    "    )\n",
    "    prismB_mask = torch.where(1.0 - ((thetaBinLerp - 0.5) * 2.0) > ratioLerp, ONE, ZERO)\n",
    "    prismC_mask = (1.0 - prismA_mask) * (1.0 - prismB_mask)\n",
    "    left_up_tetrahedron_mask_prismA = torch.where(\n",
    "        RemapTo01(lodLerp, 1.0 - ratioLerp, 1.0)\n",
    "        > RemapTo01(thetaBinLerp * 2.0, 0.0, ratioLerp),\n",
    "        ONE,\n",
    "        ZERO,\n",
    "    )\n",
    "    left_up_tetrahedron_mask_prismB = torch.where(\n",
    "        RemapTo01(lodLerp, 0.0, 1.0 - ratioLerp)\n",
    "        > RemapTo01(\n",
    "            thetaBinLerp,\n",
    "            0.5 - (1.0 - ratioLerp) * 0.5,\n",
    "            0.5 + (1.0 - ratioLerp) * 0.5,\n",
    "        ),\n",
    "        ONE,\n",
    "        ZERO,\n",
    "    )\n",
    "    left_up_tetrahedron_mask_prismC = torch.where(\n",
    "        RemapTo01(lodLerp, 1.0 - ratioLerp, 1.0)\n",
    "        > RemapTo01((thetaBinLerp - 0.5) * 2.0, 1.0 - ratioLerp, 1.0),\n",
    "        ONE,\n",
    "        ZERO,\n",
    "    )\n",
    "\n",
    "    # if (centerSpecialCase): # SPECIAL CASE (no anisotropy, center of blending pattern, different triangulation)\n",
    "    a = torch.tensor([0.0, 1.0, 0.0], requires_grad=True)\n",
    "    b = torch.tensor([0.0, 0.0, 0.0], requires_grad=True)\n",
    "    c = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "    d = torch.tensor([0.0, 1.0, 1.0], requires_grad=True)\n",
    "    e = torch.tensor([0.0, 0.0, 1.0], requires_grad=True)\n",
    "    f = torch.tensor([1.0, 1.0, 1.0], requires_grad=True)\n",
    "\n",
    "    p0 = torch.where(\n",
    "        (centerSpecialCase * upper_pyramid_mask * left_up_tetrahedron_mask).unsqueeze(\n",
    "            -1\n",
    "        )\n",
    "        * p0\n",
    "        == p0,\n",
    "        a,\n",
    "        p0,\n",
    "    )\n",
    "    p0 = torch.where(\n",
    "        (\n",
    "            centerSpecialCase * upper_pyramid_mask * (1.0 - left_up_tetrahedron_mask)\n",
    "        ).unsqueeze(-1)\n",
    "        * p0\n",
    "        == p0,\n",
    "        f,\n",
    "        p0,\n",
    "    )\n",
    "    # If a condition replaces values with b [0.0,0.0,0.0], it must be put at the end because any mask times\n",
    "    # b would result in 0.0, so the condition would always be true\n",
    "    # Need to ensures that at this stage, if condition * p0 == 0.0, it must be because condition == 0.0\n",
    "    p0 = torch.where(\n",
    "        (centerSpecialCase * (1.0 - upper_pyramid_mask)).unsqueeze(-1) * p0 == p0,\n",
    "        b,\n",
    "        p0,\n",
    "    )\n",
    "\n",
    "    # p1\n",
    "    p1 = torch.where(\n",
    "        (centerSpecialCase * upper_pyramid_mask).unsqueeze(-1) * p1 == p1, e, p1\n",
    "    )\n",
    "    p1 = torch.where(\n",
    "        (centerSpecialCase * (1.0 - upper_pyramid_mask)).unsqueeze(-1) * p1 == p1,\n",
    "        a,\n",
    "        p1,\n",
    "    )\n",
    "\n",
    "    # p2\n",
    "    p2 = torch.where(\n",
    "        (centerSpecialCase * upper_pyramid_mask * left_up_tetrahedron_mask).unsqueeze(\n",
    "            -1\n",
    "        )\n",
    "        * p2\n",
    "        == p2,\n",
    "        d,\n",
    "        p2,\n",
    "    )\n",
    "    p2 = torch.where(\n",
    "        (\n",
    "            centerSpecialCase * upper_pyramid_mask * (1.0 - left_up_tetrahedron_mask)\n",
    "        ).unsqueeze(-1)\n",
    "        * p2\n",
    "        == p2,\n",
    "        c,\n",
    "        p2,\n",
    "    )\n",
    "    p2 = torch.where(\n",
    "        (centerSpecialCase * (1.0 - upper_pyramid_mask)).unsqueeze(-1) * p2 == p2,\n",
    "        c,\n",
    "        p2,\n",
    "    )\n",
    "\n",
    "    # p3\n",
    "    p3 = torch.where(\n",
    "        (centerSpecialCase * upper_pyramid_mask * left_up_tetrahedron_mask).unsqueeze(\n",
    "            -1\n",
    "        )\n",
    "        * p3\n",
    "        == p3,\n",
    "        f,\n",
    "        p3,\n",
    "    )\n",
    "    p3 = torch.where(\n",
    "        (\n",
    "            centerSpecialCase * upper_pyramid_mask * (1.0 - left_up_tetrahedron_mask)\n",
    "        ).unsqueeze(-1)\n",
    "        * p3\n",
    "        == p3,\n",
    "        a,\n",
    "        p3,\n",
    "    )\n",
    "    p3 = torch.where(\n",
    "        (centerSpecialCase * (1.0 - upper_pyramid_mask)).unsqueeze(-1) * p3 == p3,\n",
    "        e,\n",
    "        p3,\n",
    "    )\n",
    "\n",
    "    # else: # NORMAL CASE\n",
    "    c = torch.tensor([0.5, 1.0, 0.0], requires_grad=True)\n",
    "    d = torch.tensor([1.0, 0.0, 0.0], requires_grad=True)\n",
    "    e = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "    f = torch.tensor([0.0, 1.0, 1.0], requires_grad=True)\n",
    "    g = torch.tensor([0.0, 0.0, 1.0], requires_grad=True)\n",
    "    h = torch.tensor([0.5, 1.0, 1.0], requires_grad=True)\n",
    "    i = torch.tensor([1.0, 0.0, 1.0], requires_grad=True)\n",
    "    j = torch.tensor([1.0, 1.0, 1.0], requires_grad=True)\n",
    "\n",
    "    # p0 values\n",
    "    p0 = torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismA_mask\n",
    "            * upper_pyramid_mask\n",
    "            * left_up_tetrahedron_mask_prismA\n",
    "        ).unsqueeze(-1)\n",
    "        * p0\n",
    "        == p0,\n",
    "        a,\n",
    "        p0,\n",
    "    )\n",
    "    # A tweak to calculate and & operation for floating point 1.0 and 0.0 values\n",
    "    p0_replace_with_c = (\n",
    "        normal_case_mask\n",
    "        * prismA_mask\n",
    "        * upper_pyramid_mask\n",
    "        * (1.0 - left_up_tetrahedron_mask_prismA)\n",
    "        + normal_case_mask\n",
    "        * prismC_mask\n",
    "        * upper_pyramid_mask\n",
    "        * left_up_tetrahedron_mask_prismC\n",
    "        + normal_case_mask * prismB_mask * (1.0 - lower_pyramid_mask)\n",
    "    )\n",
    "    p0 = torch.where(\n",
    "        p0_replace_with_c.unsqueeze(-1) * p0\n",
    "        != b,  # if condition * p0 == 0.0, it must be because condition == 0.0\n",
    "        c,\n",
    "        p0,\n",
    "    )\n",
    "    p0_replace_with_d = normal_case_mask * prismB_mask * lower_pyramid_mask * (\n",
    "        1.0 - left_up_tetrahedron_mask_prismB\n",
    "    ) + normal_case_mask * prismC_mask * (1.0 - upper_pyramid_mask)\n",
    "    p0 = torch.where(p0_replace_with_d.unsqueeze(-1) * p0 != b, d, p0)\n",
    "    p0 = torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismC_mask\n",
    "            * upper_pyramid_mask\n",
    "            * (1.0 - left_up_tetrahedron_mask_prismC)\n",
    "        ).unsqueeze(-1)\n",
    "        * p0\n",
    "        == p0,\n",
    "        e,\n",
    "        p0,\n",
    "    )\n",
    "\n",
    "    p0_replace_with_b = (\n",
    "        normal_case_mask * prismA_mask * (1.0 - upper_pyramid_mask)\n",
    "        + normal_case_mask\n",
    "        * prismB_mask\n",
    "        * lower_pyramid_mask\n",
    "        * left_up_tetrahedron_mask_prismB\n",
    "    )\n",
    "    p0 = torch.where(p0_replace_with_b.unsqueeze(-1) * p0 != b, b, p0)\n",
    "\n",
    "    # p1\n",
    "    p1 = torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismA_mask\n",
    "            * upper_pyramid_mask\n",
    "            * left_up_tetrahedron_mask_prismA\n",
    "        ).unsqueeze(-1)\n",
    "        * p1\n",
    "        == p1,\n",
    "        f,\n",
    "        p1,\n",
    "    )\n",
    "    p1_replace_with_a = normal_case_mask * prismA_mask * upper_pyramid_mask * (\n",
    "        1.0 - left_up_tetrahedron_mask_prismA\n",
    "    ) + normal_case_mask * prismA_mask * (1.0 - upper_pyramid_mask)\n",
    "    p1 = torch.where(p1_replace_with_a.unsqueeze(-1) * p1 != b, a, p1)\n",
    "    p1_replace_with_g = (\n",
    "        normal_case_mask\n",
    "        * prismB_mask\n",
    "        * lower_pyramid_mask\n",
    "        * left_up_tetrahedron_mask_prismB\n",
    "        + normal_case_mask * prismB_mask * (1.0 - lower_pyramid_mask)\n",
    "    )\n",
    "    p1 = torch.where(p1_replace_with_g.unsqueeze(-1) * p1 != b, g, p1)\n",
    "    p1 = torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismC_mask\n",
    "            * upper_pyramid_mask\n",
    "            * left_up_tetrahedron_mask_prismC\n",
    "        ).unsqueeze(-1)\n",
    "        * p1\n",
    "        == p1,\n",
    "        j,\n",
    "        p1,\n",
    "    )\n",
    "    p1 = torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismC_mask\n",
    "            * upper_pyramid_mask\n",
    "            * (1.0 - left_up_tetrahedron_mask_prismC)\n",
    "        ).unsqueeze(-1)\n",
    "        * p1\n",
    "        == p1,\n",
    "        i,\n",
    "        p1,\n",
    "    )\n",
    "    p1 = torch.where(\n",
    "        (normal_case_mask * prismC_mask * (1.0 - upper_pyramid_mask)).unsqueeze(-1) * p1\n",
    "        == p1,\n",
    "        e,\n",
    "        p1,\n",
    "    )\n",
    "\n",
    "    p1 = torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismB_mask\n",
    "            * lower_pyramid_mask\n",
    "            * (1.0 - left_up_tetrahedron_mask_prismB)\n",
    "        ).unsqueeze(-1)\n",
    "        * p1\n",
    "        == p1,\n",
    "        b,\n",
    "        p1,\n",
    "    )\n",
    "\n",
    "    # p2\n",
    "    p2_replace_with_h = (\n",
    "        normal_case_mask * prismA_mask * upper_pyramid_mask\n",
    "        + normal_case_mask * prismB_mask * (1.0 - lower_pyramid_mask)\n",
    "        + normal_case_mask\n",
    "        * prismC_mask\n",
    "        * upper_pyramid_mask\n",
    "        * left_up_tetrahedron_mask_prismC\n",
    "    )\n",
    "    p2 = torch.where(p2_replace_with_h.unsqueeze(-1) * p2 != b, h, p2)\n",
    "    p2_replace_with_c = (\n",
    "        normal_case_mask * prismA_mask * (1.0 - upper_pyramid_mask)\n",
    "        + normal_case_mask\n",
    "        * prismB_mask\n",
    "        * lower_pyramid_mask\n",
    "        * (1.0 - left_up_tetrahedron_mask_prismB)\n",
    "        + normal_case_mask\n",
    "        * prismC_mask\n",
    "        * upper_pyramid_mask\n",
    "        * (1.0 - left_up_tetrahedron_mask_prismC)\n",
    "        + normal_case_mask * prismC_mask * (1.0 - upper_pyramid_mask)\n",
    "    )\n",
    "    p2 = torch.where(p2_replace_with_c.unsqueeze(-1) * p2 != b, c, p2)\n",
    "    torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismB_mask\n",
    "            * lower_pyramid_mask\n",
    "            * left_up_tetrahedron_mask_prismB\n",
    "        ).unsqueeze(-1)\n",
    "        * p2\n",
    "        == p2,\n",
    "        i,\n",
    "        p2,\n",
    "    )\n",
    "\n",
    "    # p3\n",
    "    p3 = torch.where((normal_case_mask * prismA_mask).unsqueeze(-1) * p3 == p3, g, p3)\n",
    "    p3 = torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismB_mask\n",
    "            * lower_pyramid_mask\n",
    "            * left_up_tetrahedron_mask_prismB\n",
    "        ).unsqueeze(-1)\n",
    "        * p3\n",
    "        == p3,\n",
    "        c,\n",
    "        p3,\n",
    "    )\n",
    "    p3_replace_with_i = (\n",
    "        normal_case_mask\n",
    "        * prismB_mask\n",
    "        * lower_pyramid_mask\n",
    "        * (1.0 - left_up_tetrahedron_mask_prismB)\n",
    "        + normal_case_mask * prismB_mask * (1.0 - lower_pyramid_mask)\n",
    "        + normal_case_mask\n",
    "        * prismC_mask\n",
    "        * upper_pyramid_mask\n",
    "        * left_up_tetrahedron_mask_prismC\n",
    "        + normal_case_mask * prismC_mask * (1.0 - upper_pyramid_mask)\n",
    "    )\n",
    "    p3 = torch.where(p3_replace_with_i.unsqueeze(-1) * p3 != b, i, p3)\n",
    "    p3 = torch.where(\n",
    "        (\n",
    "            normal_case_mask\n",
    "            * prismC_mask\n",
    "            * upper_pyramid_mask\n",
    "            * (1.0 - left_up_tetrahedron_mask_prismC)\n",
    "        ).unsqueeze(-1)\n",
    "        * p3\n",
    "        == p3,\n",
    "        j,\n",
    "        p3,\n",
    "    )\n",
    "\n",
    "    return p0, p1, p2, p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.884339300Z",
     "start_time": "2023-10-20T10:52:58.795499300Z"
    }
   },
   "outputs": [],
   "source": [
    "# @param localHalfVector: float3\n",
    "# @param targetNDF: float\n",
    "# @param maxNDF: float\n",
    "# @param uv: float2\n",
    "# @param duvdx: float2\n",
    "# @param duvdy: float2\n",
    "#\n",
    "# @return float4\n",
    "def SampleGlints2023NDF(localHalfVector, targetNDF, maxNDF, uv, duvdx, duvdy):\n",
    "    ellipseMajor, ellipseMinor = GetGradientEllipse(duvdx, duvdy)\n",
    "    ellipseRatio = torch.norm(ellipseMajor, dim=-1) / torch.norm(ellipseMinor, dim=-1)\n",
    "\n",
    "    # SHARED GLINT NDF VALUES\n",
    "    halfScreenSpaceScaler = _ScreenSpaceScale * 0.5\n",
    "    slope = localHalfVector[..., :2]  # Orthogrtaphic slope projected grid\n",
    "    rescaledTargetNDF = targetNDF / maxNDF\n",
    "\n",
    "    # MANUAL LOD COMPENSATION\n",
    "    lod = torch.log2(torch.norm(ellipseMinor, dim=-1) * halfScreenSpaceScaler)\n",
    "    # TODO: lod0 = lod.to(torch.int).to(torch.float) # lod >= 0.0 ? (int)(lod) : (int)(lod - 1.0)\n",
    "    lod0 = toIntApprox(lod)\n",
    "    lod1 = lod0 + 1\n",
    "    divLod0 = torch.pow(torch.tensor(2.0), lod0)\n",
    "    divLod1 = torch.pow(torch.tensor(2.0), lod1)\n",
    "    lodLerp = torch.frac(lod)\n",
    "    footprintAreaLOD0 = torch.pow(torch.exp2(lod0), 2.0)\n",
    "    footprintAreaLOD1 = torch.pow(torch.exp2(lod1), 2.0)\n",
    "\n",
    "    # MANUAL ANISOTROPY RATIO COMPENSATION\n",
    "    # TODO: ratio0 = torch.max(torch.pow(torch.tensor(2.0), torch.log2(ellipseRatio).to(torch.int)), torch.tensor(1.0))\n",
    "    ratio0 = torch.clamp(\n",
    "        torch.pow(\n",
    "            torch.tensor(2.0, requires_grad=True),\n",
    "            torch.log2(ellipseRatio).to(torch.int),\n",
    "        ),\n",
    "        1.0,\n",
    "    )\n",
    "    ratio1 = ratio0 * 2.0\n",
    "    ratioLerp = torch.clamp(Remap(ellipseRatio, ratio0, ratio1, 0.0, 1.0), 0.0, 1.0)\n",
    "\n",
    "    # MANUAL ANISOTROPY ROTATION COMPENSATION\n",
    "    v1 = torch.tensor([0.0, 1.0], requires_grad=True)\n",
    "    v2 = torch.nn.functional.normalize(ellipseMajor, dim=-1)\n",
    "    theta = (\n",
    "        torch.atan2(\n",
    "            v1[0] * v2[..., 1] - v1[1] * v2[..., 0],\n",
    "            v1[0] * v2[..., 0] + v1[1] * v2[..., 1],\n",
    "        )\n",
    "        * RAD2DEG\n",
    "    )\n",
    "    thetaGrid = 90.0 / torch.clamp(ratio0, 2.0)\n",
    "    # TODO: thetaBin = (theta / thetaGrid).to(torch.int) * thetaGrid\n",
    "    thetaBin = toIntApprox(theta / thetaGrid) * thetaGrid\n",
    "    thetaBin += thetaGrid / 2.0\n",
    "    thetaBin0 = torch.where(theta < thetaBin, thetaBin - thetaGrid / 2.0, thetaBin)\n",
    "    thetaBinH = thetaBin0 + thetaGrid / 4.0\n",
    "    thetaBin1 = thetaBin0 + thetaGrid / 2.0\n",
    "    thetaBinLerp = Remap(theta, thetaBin0, thetaBin1, 0.0, 1.0)\n",
    "    thetaBin0 = torch.where(thetaBin0 <= 0.0, 180.0 + thetaBin0, thetaBin0)\n",
    "\n",
    "    # TETRAHEDRONIZATION OF ROTATION + RATIO + LOD GRID\n",
    "    # TODO: centerSpecialCase = (ratio0 == 1.0)\n",
    "    centerSpecialCase = torch.where(ratio0 == 1.0, ratio0, ZERO)\n",
    "    divLods = torch.stack((divLod0, divLod1), dim=-1)\n",
    "    footprintAreas = torch.stack((footprintAreaLOD0, footprintAreaLOD1), dim=-1)\n",
    "    ratios = torch.stack((ratio0, ratio1), dim=-1)\n",
    "    thetaBins = torch.stack(\n",
    "        (thetaBin0, thetaBinH, thetaBin1, torch.zeros(thetaBin0.shape)),\n",
    "        dim=-1,\n",
    "    )  # added 0.0 for center singularity case\n",
    "    tetraA, tetraB, tetraC, tetraD = GetAnisoCorrectingGridTetrahedron(\n",
    "        centerSpecialCase, thetaBinLerp, ratioLerp, lodLerp\n",
    "    )\n",
    "    # TODO: thetaBinLerp[centerSpecialCase] = Remap01To(thetaBinLerp[centerSpecialCase], 0.0, ratioLerp[centerSpecialCase])\n",
    "    # Account for center singularity in barycentric computation\n",
    "    thetaBinLerp = torch.where(\n",
    "        centerSpecialCase == 1.0,\n",
    "        Remap01To(thetaBinLerp, 0.0, ratioLerp),\n",
    "        thetaBinLerp,\n",
    "    )\n",
    "    tetraBarycentricWeights = GetBarycentricWeightsTetrahedron(\n",
    "        torch.stack((thetaBinLerp, ratioLerp, lodLerp), dim=-1),\n",
    "        tetraA,\n",
    "        tetraB,\n",
    "        tetraC,\n",
    "        tetraD,\n",
    "    )  # Compute barycentric coordinates within chosen tetrahedron\n",
    "\n",
    "    # PREPARE NEEDED ROTATIONS\n",
    "    tetraA[..., 0] *= 2\n",
    "    tetraB[..., 0] *= 2\n",
    "    tetraC[..., 0] *= 2\n",
    "    tetraD[..., 0] *= 2\n",
    "\n",
    "    # if (centerSpecialCase): # Account for center singularity (if center vertex => no rotation)\n",
    "    # TODO: tetraA[centerSpecialCase][..., 0] = torch.where(tetraA[centerSpecialCase][..., 1] == 0.0, 3.0, tetraA[centerSpecialCase][..., 0])\n",
    "    # tetraB[centerSpecialCase][..., 0] = torch.where(tetraB[centerSpecialCase][..., 1] == 0.0, 3.0, tetraB[centerSpecialCase][..., 0])\n",
    "    # tetraC[centerSpecialCase][..., 0] = torch.where(tetraC[centerSpecialCase][..., 1] == 0.0, 3.0, tetraC[centerSpecialCase][..., 0])\n",
    "    # tetraD[centerSpecialCase][..., 0] = torch.where(tetraD[centerSpecialCase][..., 1] == 0.0, 3.0, tetraD[centerSpecialCase][..., 0])\n",
    "    three = torch.tensor(3.0, requires_grad=True)\n",
    "    tetraA[..., 0] = torch.where(\n",
    "        centerSpecialCase == 1.0,\n",
    "        torch.where(tetraA[..., 1] == 0.0, three, tetraA[..., 0]),\n",
    "        tetraA[..., 0],\n",
    "    )\n",
    "    tetraB[..., 0] = torch.where(\n",
    "        centerSpecialCase == 1.0,\n",
    "        torch.where(tetraB[..., 1] == 0.0, three, tetraB[..., 0]),\n",
    "        tetraB[..., 0],\n",
    "    )\n",
    "    tetraC[..., 0] = torch.where(\n",
    "        centerSpecialCase == 1.0,\n",
    "        torch.where(tetraC[..., 1] == 0.0, three, tetraC[..., 0]),\n",
    "        tetraC[..., 0],\n",
    "    )\n",
    "    tetraD[..., 0] = torch.where(\n",
    "        centerSpecialCase == 1.0,\n",
    "        torch.where(tetraD[..., 1] == 0.0, three, tetraD[..., 0]),\n",
    "        tetraD[..., 0],\n",
    "    )\n",
    "\n",
    "    # selections based on tetra values\n",
    "    # TODO: thetaBins_tetraA = thetaBins[torch.arange(len(thetaBins)), tetraA[...,0].to(torch.int)]\n",
    "    # thetaBins_tetraB = thetaBins[torch.arange(len(thetaBins)), tetraB[...,0].to(torch.int)]\n",
    "    # thetaBins_tetraC = thetaBins[torch.arange(len(thetaBins)), tetraC[...,0].to(torch.int)]\n",
    "    # thetaBins_tetraD = thetaBins[torch.arange(len(thetaBins)), tetraD[...,0].to(torch.int)]\n",
    "    zeros = torch.zeros(tetraA.shape[0], 1, requires_grad=True)\n",
    "    thetaBins_tetraA = torch.gather(\n",
    "        thetaBins, dim=-1, index=torch.cat((tetraA, zeros), dim=-1).to(torch.int64)\n",
    "    )[..., 0]\n",
    "    thetaBins_tetraB = torch.gather(\n",
    "        thetaBins, dim=-1, index=torch.cat((tetraB, zeros), dim=-1).to(torch.int64)\n",
    "    )[..., 0]\n",
    "    thetaBins_tetraC = torch.gather(\n",
    "        thetaBins, dim=-1, index=torch.cat((tetraC, zeros), dim=-1).to(torch.int64)\n",
    "    )[..., 0]\n",
    "    thetaBins_tetraD = torch.gather(\n",
    "        thetaBins, dim=-1, index=torch.cat((tetraD, zeros), dim=-1).to(torch.int64)\n",
    "    )[..., 0]\n",
    "    # TODO: divLods_tetraA = divLods[torch.arange(len(divLods)), tetraA[...,2].to(torch.int)]\n",
    "    # divLods_tetraB = divLods[torch.arange(len(divLods)), tetraB[...,2].to(torch.int)]\n",
    "    # divLods_tetraC = divLods[torch.arange(len(divLods)), tetraC[...,2].to(torch.int)]\n",
    "    # divLods_tetraD = divLods[torch.arange(len(divLods)), tetraD[...,2].to(torch.int)]\n",
    "    divLods_tetraA = torch.gather(divLods, dim=-1, index=tetraA[:, 1:].to(torch.int64))[\n",
    "        ..., 1\n",
    "    ]\n",
    "    divLods_tetraB = torch.gather(divLods, dim=-1, index=tetraB[:, 1:].to(torch.int64))[\n",
    "        ..., 1\n",
    "    ]\n",
    "    divLods_tetraC = torch.gather(divLods, dim=-1, index=tetraC[:, 1:].to(torch.int64))[\n",
    "        ..., 1\n",
    "    ]\n",
    "    divLods_tetraD = torch.gather(divLods, dim=-1, index=tetraD[:, 1:].to(torch.int64))[\n",
    "        ..., 1\n",
    "    ]\n",
    "    # TODO: ratios_tetraA = ratios[torch.arange(len(ratios)), tetraA[...,1].to(torch.int)]\n",
    "    # ratios_tetraB = ratios[torch.arange(len(ratios)), tetraB[...,1].to(torch.int)]\n",
    "    # ratios_tetraC = ratios[torch.arange(len(ratios)), tetraC[...,1].to(torch.int)]\n",
    "    # ratios_tetraD = ratios[torch.arange(len(ratios)), tetraD[...,1].to(torch.int)]\n",
    "    ratios_tetraA = torch.gather(ratios, dim=-1, index=tetraA[:, 1:].to(torch.int64))[\n",
    "        ..., 0\n",
    "    ]\n",
    "    ratios_tetraB = torch.gather(ratios, dim=-1, index=tetraB[:, 1:].to(torch.int64))[\n",
    "        ..., 0\n",
    "    ]\n",
    "    ratios_tetraC = torch.gather(ratios, dim=-1, index=tetraC[:, 1:].to(torch.int64))[\n",
    "        ..., 0\n",
    "    ]\n",
    "    ratios_tetraD = torch.gather(ratios, dim=-1, index=tetraD[:, 1:].to(torch.int64))[\n",
    "        ..., 0\n",
    "    ]\n",
    "    # TODO: footprintAreas_tetraA = footprintAreas[torch.arange(len(footprintAreas)), tetraA[...,2].to(torch.int)]\n",
    "    # footprintAreas_tetraB = footprintAreas[torch.arange(len(footprintAreas)), tetraB[...,2].to(torch.int)]\n",
    "    # footprintAreas_tetraC = footprintAreas[torch.arange(len(footprintAreas)), tetraC[...,2].to(torch.int)]\n",
    "    # footprintAreas_tetraD = footprintAreas[torch.arange(len(footprintAreas)), tetraD[...,2].to(torch.int)]\n",
    "    footprintAreas_tetraA = torch.gather(\n",
    "        footprintAreas, dim=-1, index=tetraA[:, 1:].to(torch.int64)\n",
    "    )[..., 1]\n",
    "    footprintAreas_tetraB = torch.gather(\n",
    "        footprintAreas, dim=-1, index=tetraB[:, 1:].to(torch.int64)\n",
    "    )[..., 1]\n",
    "    footprintAreas_tetraC = torch.gather(\n",
    "        footprintAreas, dim=-1, index=tetraC[:, 1:].to(torch.int64)\n",
    "    )[..., 1]\n",
    "    footprintAreas_tetraD = torch.gather(\n",
    "        footprintAreas, dim=-1, index=tetraD[:, 1:].to(torch.int64)\n",
    "    )[..., 1]\n",
    "\n",
    "    uvRotA = RotateUV(\n",
    "        uv,\n",
    "        thetaBins_tetraA * DEG2RAD,\n",
    "        torch.full((2,), 0.0, requires_grad=True),\n",
    "    )\n",
    "    uvRotB = RotateUV(\n",
    "        uv,\n",
    "        thetaBins_tetraB * DEG2RAD,\n",
    "        torch.full((2,), 0.0, requires_grad=True),\n",
    "    )\n",
    "    uvRotC = RotateUV(\n",
    "        uv,\n",
    "        thetaBins_tetraC * DEG2RAD,\n",
    "        torch.full((2,), 0.0, requires_grad=True),\n",
    "    )\n",
    "    uvRotD = RotateUV(\n",
    "        uv,\n",
    "        thetaBins_tetraD * DEG2RAD,\n",
    "        torch.full((2,), 0.0, requires_grad=True),\n",
    "    )\n",
    "\n",
    "    # SAMPLE GLINT GRIDS\n",
    "    # a float is returned\n",
    "    # gridSeedA = np.uint32(HashWithoutSine13(torch.stack((torch.log2(divLods_tetraA), thetaBins_tetraA % 360, ratios_tetraA), dim=-1))* 4294967296.0)\n",
    "    # gridSeedB = np.uint32(HashWithoutSine13(torch.stack((torch.log2(divLods_tetraB), thetaBins_tetraB % 360, ratios_tetraB), dim=-1))* 4294967296.0)\n",
    "    # gridSeedC = np.uint32(HashWithoutSine13(torch.stack((torch.log2(divLods_tetraC), thetaBins_tetraC % 360, ratios_tetraC), dim=-1))* 4294967296.0)\n",
    "    # gridSeedD = np.uint32(HashWithoutSine13(torch.stack((torch.log2(divLods_tetraD), thetaBins_tetraD % 360, ratios_tetraD), dim=-1))* 4294967296.0)\n",
    "    gridSeedA = (\n",
    "        HashWithoutSine13(\n",
    "            torch.stack(\n",
    "                (torch.log2(divLods_tetraA), thetaBins_tetraA % 360, ratios_tetraA),\n",
    "                dim=-1,\n",
    "            )\n",
    "        )\n",
    "        * 4294967296.0\n",
    "    )\n",
    "    gridSeedB = (\n",
    "        HashWithoutSine13(\n",
    "            torch.stack(\n",
    "                (torch.log2(divLods_tetraB), thetaBins_tetraB % 360, ratios_tetraB),\n",
    "                dim=-1,\n",
    "            )\n",
    "        )\n",
    "        * 4294967296.0\n",
    "    )\n",
    "    gridSeedC = (\n",
    "        HashWithoutSine13(\n",
    "            torch.stack(\n",
    "                (torch.log2(divLods_tetraC), thetaBins_tetraC % 360, ratios_tetraC),\n",
    "                dim=-1,\n",
    "            )\n",
    "        )\n",
    "        * 4294967296.0\n",
    "    )\n",
    "    gridSeedD = (\n",
    "        HashWithoutSine13(\n",
    "            torch.stack(\n",
    "                (torch.log2(divLods_tetraD), thetaBins_tetraD % 360, ratios_tetraD),\n",
    "                dim=-1,\n",
    "            )\n",
    "        )\n",
    "        * 4294967296.0\n",
    "    )\n",
    "\n",
    "    ones = torch.ones(ratios_tetraA.shape, requires_grad=True)\n",
    "    sampleA = SampleGlintGridSimplex(\n",
    "        uvRotA\n",
    "        / divLods_tetraA.unsqueeze(-1)\n",
    "        / torch.stack((ones, ratios_tetraA), dim=-1),\n",
    "        gridSeedA,\n",
    "        slope,\n",
    "        ratios_tetraA * footprintAreas_tetraA,\n",
    "        rescaledTargetNDF,\n",
    "        tetraBarycentricWeights[..., 0],\n",
    "    )\n",
    "    sampleB = SampleGlintGridSimplex(\n",
    "        uvRotB\n",
    "        / divLods_tetraB.unsqueeze(-1)\n",
    "        / torch.stack((ones, ratios_tetraB), dim=-1),\n",
    "        gridSeedB,\n",
    "        slope,\n",
    "        ratios_tetraB * footprintAreas_tetraB,\n",
    "        rescaledTargetNDF,\n",
    "        tetraBarycentricWeights[..., 1],\n",
    "    )\n",
    "    sampleC = SampleGlintGridSimplex(\n",
    "        uvRotC\n",
    "        / divLods_tetraC.unsqueeze(-1)\n",
    "        / torch.stack((ones, ratios_tetraC), dim=-1),\n",
    "        gridSeedC,\n",
    "        slope,\n",
    "        ratios_tetraC * footprintAreas_tetraC,\n",
    "        rescaledTargetNDF,\n",
    "        tetraBarycentricWeights[..., 2],\n",
    "    )\n",
    "    sampleD = SampleGlintGridSimplex(\n",
    "        uvRotD\n",
    "        / divLods_tetraD.unsqueeze(-1)\n",
    "        / torch.stack((ones, ratios_tetraD), dim=-1),\n",
    "        gridSeedD,\n",
    "        slope,\n",
    "        ratios_tetraD * footprintAreas_tetraD,\n",
    "        rescaledTargetNDF,\n",
    "        tetraBarycentricWeights[..., 3],\n",
    "    )\n",
    "\n",
    "    res = (\n",
    "        (sampleA + sampleB + sampleC + sampleD) * (1.0 / _MicrofacetRoughness) * maxNDF\n",
    "    )\n",
    "    \n",
    "    res = normalise(res)\n",
    "\n",
    "    print(\n",
    "        f\"min: {torch.min(res)}, max: {torch.max(res)}, median: {torch.median(res)}, mean: {torch.mean(res)}\"\n",
    "    )\n",
    "\n",
    "    assert is_valid(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Calling the Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T10:52:58.899499300Z",
     "start_time": "2023-10-20T10:52:58.844283500Z"
    }
   },
   "outputs": [],
   "source": [
    "localHalfVector = torch.rand((num_vals, 3), requires_grad=True)\n",
    "targetNDF = torch.rand((num_vals,), requires_grad=True)\n",
    "maxNDF = torch.rand((num_vals,), requires_grad=True)\n",
    "uv = torch.rand((num_vals, 2), requires_grad=True)\n",
    "duvdx = torch.rand((num_vals, 2), requires_grad=True)\n",
    "duvdy = torch.rand((num_vals, 2), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:53:00.924407600Z",
     "start_time": "2023-10-20T10:52:58.858336600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.0, max: 1.0, median: 0.009127961471676826, mean: 0.011039678007364273\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.0092, 0.0091, 0.0097,  ..., 0.0091, 0.0092, 0.0091],\n       grad_fn=<DivBackward0>)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "res = SampleGlints2023NDF(localHalfVector, targetNDF, maxNDF, uv, duvdx, duvdy)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:53:00.993111200Z",
     "start_time": "2023-10-20T10:53:00.921893300Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_tensor(tensor):\n",
    "    if torch.any(torch.isnan(tensor)):\n",
    "        print(\"Nan found.\")\n",
    "    if torch.any(torch.isinf(tensor)):\n",
    "        print(\"Inf found.\")\n",
    "    if tensor.grad_fn is None:\n",
    "        print(\"No gradient.\")\n",
    "    if (\n",
    "        not torch.any(torch.isnan(tensor))\n",
    "        and not torch.any(torch.isinf(tensor))\n",
    "        and tensor.grad_fn is not None\n",
    "    ):\n",
    "        print(\"All good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:53:01.043116600Z",
     "start_time": "2023-10-20T10:53:00.936868700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good.\n"
     ]
    }
   ],
   "source": [
    "validate_tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T10:53:01.044116Z",
     "start_time": "2023-10-20T10:53:00.953368500Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.autograd.gradcheck(SampleGlints2023NDF, (localHalfVector, targetNDF, maxNDF, uv, duvdx, duvdy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
